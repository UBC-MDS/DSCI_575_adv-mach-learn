{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zg8CaVExFp6l"
   },
   "source": [
    "## Character-level text generation using LSTMs\n",
    "\n",
    "Before we have seen how to generate text using Markov models. In this tutorial, we will see how can we do it using RNNs. \n",
    "\n",
    "LSTMs are expensive to train and, I recommend that you run this on the cloud using [Google colab](https://colab.research.google.com/notebooks/welcome.ipynb). This will allow you to train on a GPU and assess the benefits of training neural networks on GPUs.\n",
    "\n",
    "You will follow the steps below.\n",
    "\n",
    "- Go to [Google colab](https://colab.research.google.com/). \n",
    "- Make an account if you don't have one.\n",
    "- Select \"UPLOAD\" and upload this notebook. \n",
    "- Runtime --> change runtime type --> Select GPU.\n",
    "- Run the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YszL3gQYFklW"
   },
   "source": [
    "\n",
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEUqjwio47pl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpHweX0E5EZK"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qne04EmQG7qd"
   },
   "source": [
    "## Read the data\n",
    "\n",
    "I have created a toy corpus in the students directory and we'll be working with this corpus in this demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Q3UgfLikG2n"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "data_url = 'https://raw.github.ubc.ca/MDS-2019-20/DSCI_575_adv-mach-learn_students/master/lectures/data/toy_cohen_poetry.txt?token=AAAANPYW3MZ66UPOTCMGER26UZKPM'\n",
    "text = urlopen(data_url).read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1587357757139,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "bAcv352r51q2",
    "outputId": "73f0659f-c4a4-4273-e5c3-0ec0b303e200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the birds they sang\n",
      "at the break of day\n",
      "start again\n",
      "i heard them say\n",
      "don't dwell on what\n",
      "has passed away\n",
      "or what is yet to be\n",
      "yeah the wars they will\n",
      "be fought again\n",
      "the holy dove\n",
      "she will be caught again\n",
      "bought and sold\n",
      "and bought again\n",
      "the dove is \n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "text = text.lower()\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2537,
     "status": "ok",
     "timestamp": 1587357757140,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "FmviIyrb6BYT",
    "outputId": "f2b0ebb1-4753-4c2b-8f26-423bbf6bb023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QeoikMFaHnlf"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Let's prepare our text so that we can feed it into an RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfopdYbmH1Kp"
   },
   "source": [
    "### Vectorize the text\n",
    "\n",
    "- Map unique characters to indices. \n",
    "- Represent a sequence of characters as a sequence of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FA3bdqDZ6Iaw"
   },
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2503,
     "status": "ok",
     "timestamp": 1587357757141,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "ZEDnplsW6MaN",
    "outputId": "19e83e40-4101-43a8-aeac-6c44b91343ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '\"' :   2,\n",
      "  \"'\" :   3,\n",
      "  '(' :   4,\n",
      "  ')' :   5,\n",
      "  ',' :   6,\n",
      "  '.' :   7,\n",
      "  '?' :   8,\n",
      "  'a' :   9,\n",
      "  'b' :  10,\n",
      "  'c' :  11,\n",
      "  'd' :  12,\n",
      "  'e' :  13,\n",
      "  'f' :  14,\n",
      "  'g' :  15,\n",
      "  'h' :  16,\n",
      "  'i' :  17,\n",
      "  'j' :  18,\n",
      "  'k' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiEeBmIZE22E"
   },
   "outputs": [],
   "source": [
    "n_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UobjSgfZJEez"
   },
   "source": [
    "### Create `X` and `y`\n",
    "\n",
    "Our prediction task is: Given or a sequence of characters, what is the most likely character? Remember that in RNNs, we maintain the hidden state that maintains information about all the input we have seen so far. \n",
    "\n",
    "- So first design decision is how long we want to maintain this information. We define a `seq_length` and remember the information for that much time. You can roughly think of this as `n` in your n-gram model.\n",
    "\n",
    "- So `X` is going to be sequence of characters and `y` is going to be the next character. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDwkW7xru5BQ"
   },
   "source": [
    "With the LSTM, the data matrix `X` is now 3-dimensional instead of 2-dimensional. The dimensions are\n",
    "\n",
    "- number training examples\n",
    "- sequence length (this is the `n`  of the  `n-grams`)\n",
    "- number of features, which in this case is a 1-hot encoding of the  ùëë  characters in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4dmU5UGMtFU"
   },
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 25\n",
    "n_examples = len(text) - seq_length\n",
    "\n",
    "# Let's create X and y\n",
    "data_X = np.zeros((n_examples, seq_length, n_vocab),dtype=bool)\n",
    "data_y = np.zeros((n_examples, n_vocab))\n",
    "\n",
    "count = 10    \n",
    "for i in range(n_examples):\n",
    "    seq_in = text[i:i + seq_length]\n",
    "    char_out = text[i + seq_length]\n",
    "    for j, char in enumerate(seq_in):\n",
    "        data_X[i, j, char2idx[char]] = 1.0\n",
    "    data_y[i, char2idx[char_out]] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2464,
     "status": "ok",
     "timestamp": 1587357757145,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "2QmoL5MZwDfV",
    "outputId": "e04757c9-2624-4c66-bced-83715c0b6495"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False,  True, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False,  True, False, ..., False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at X\n",
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2450,
     "status": "ok",
     "timestamp": 1587357757146,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "Wt_1ZZT-b5r5",
    "outputId": "6a86ca5f-2783-4b77-e22b-abb5ddcfd135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at y\n",
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2431,
     "status": "ok",
     "timestamp": 1587357757148,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "4IiGKLjkQCqL",
    "outputId": "ce68db5f-0385-40c7-877b-ddf75487e6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 4419\n",
      "Total examples: 4419\n"
     ]
    }
   ],
   "source": [
    "# How many examples do we have? \n",
    "print('Total examples: %d'%(len(data_X)))\n",
    "print('Total examples: %d'%(len(data_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgUE73-lyZl6"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Let's build an LSTM model with just one layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6H9FoN-3chL"
   },
   "outputs": [],
   "source": [
    "def create_model(seq_length, \n",
    "                 n_vocab, \n",
    "                 layer_size=256, \n",
    "                 dropout_amount=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(layer_size, input_shape=(seq_length, n_vocab), \n",
    "                   return_sequences=True))\n",
    "    model.add(Dropout(dropout_amount))\n",
    "    model.add(LSTM(layer_size, return_sequences=True))\n",
    "    model.add(Dropout(dropout_amount))\n",
    "    model.add(LSTM(layer_size))\n",
    "    model.add(Dropout(dropout_amount))\n",
    "    model.add(Dense(n_vocab, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4301,
     "status": "ok",
     "timestamp": 1587357759064,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "td1op_efGMyT",
    "outputId": "d0d5ad46-de09-477a-d1fc-233a690d8b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 25, 256)           297984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 34)                8738      \n",
      "=================================================================\n",
      "Total params: 1,357,346\n",
      "Trainable params: 1,357,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_examples, seq_length, n_vocab = data_X.shape\n",
    "\n",
    "model = create_model(seq_length, n_vocab)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62414,
     "status": "ok",
     "timestamp": 1587357817201,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "U4XXVGLRGCSH",
    "outputId": "924474c7-241c-4eb9-ec28-a7ddbc76415b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 3.1666 - accuracy: 0.1330 - val_loss: 2.9809 - val_accuracy: 0.1618\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3.0233 - accuracy: 0.1562 - val_loss: 2.9578 - val_accuracy: 0.1618\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.0136 - accuracy: 0.1610 - val_loss: 2.9875 - val_accuracy: 0.1618\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.9990 - accuracy: 0.1595 - val_loss: 2.9627 - val_accuracy: 0.1618\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.9836 - accuracy: 0.1593 - val_loss: 2.9510 - val_accuracy: 0.1618\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.9730 - accuracy: 0.1567 - val_loss: 2.9486 - val_accuracy: 0.1618\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.9496 - accuracy: 0.1610 - val_loss: 2.9675 - val_accuracy: 0.1527\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.9115 - accuracy: 0.1632 - val_loss: 2.9681 - val_accuracy: 0.1346\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.8840 - accuracy: 0.1646 - val_loss: 2.9554 - val_accuracy: 0.1584\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.8539 - accuracy: 0.1655 - val_loss: 2.9713 - val_accuracy: 0.1493\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.8270 - accuracy: 0.1686 - val_loss: 2.9495 - val_accuracy: 0.1527\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.7935 - accuracy: 0.1737 - val_loss: 2.9596 - val_accuracy: 0.1538\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.7728 - accuracy: 0.1782 - val_loss: 2.9700 - val_accuracy: 0.1516\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.7322 - accuracy: 0.1921 - val_loss: 2.9451 - val_accuracy: 0.1584\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.6958 - accuracy: 0.1893 - val_loss: 2.9392 - val_accuracy: 0.1538\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.6602 - accuracy: 0.1994 - val_loss: 2.9620 - val_accuracy: 0.1448\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.6370 - accuracy: 0.2031 - val_loss: 2.9580 - val_accuracy: 0.1561\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.5893 - accuracy: 0.2161 - val_loss: 2.9487 - val_accuracy: 0.1584\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.5714 - accuracy: 0.2136 - val_loss: 2.9195 - val_accuracy: 0.1606\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.5416 - accuracy: 0.2229 - val_loss: 2.9330 - val_accuracy: 0.1561\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.4893 - accuracy: 0.2342 - val_loss: 2.9737 - val_accuracy: 0.1550\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.4451 - accuracy: 0.2393 - val_loss: 2.9968 - val_accuracy: 0.1561\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.4159 - accuracy: 0.2574 - val_loss: 2.9615 - val_accuracy: 0.1584\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.3780 - accuracy: 0.2588 - val_loss: 2.9650 - val_accuracy: 0.1527\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.3247 - accuracy: 0.2769 - val_loss: 2.9425 - val_accuracy: 0.1663\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.2606 - accuracy: 0.2999 - val_loss: 2.9321 - val_accuracy: 0.1674\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.2229 - accuracy: 0.2982 - val_loss: 2.9670 - val_accuracy: 0.1889\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.1714 - accuracy: 0.3256 - val_loss: 2.9611 - val_accuracy: 0.1844\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.0801 - accuracy: 0.3516 - val_loss: 2.9174 - val_accuracy: 0.2025\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.0094 - accuracy: 0.3728 - val_loss: 2.9428 - val_accuracy: 0.2081\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.9794 - accuracy: 0.3686 - val_loss: 2.9152 - val_accuracy: 0.2093\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.9004 - accuracy: 0.4000 - val_loss: 2.9608 - val_accuracy: 0.2240\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.8544 - accuracy: 0.4119 - val_loss: 2.9842 - val_accuracy: 0.2014\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.7727 - accuracy: 0.4379 - val_loss: 3.0038 - val_accuracy: 0.2285\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.7255 - accuracy: 0.4498 - val_loss: 3.0285 - val_accuracy: 0.2376\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.6372 - accuracy: 0.4716 - val_loss: 3.1261 - val_accuracy: 0.2330\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6000 - accuracy: 0.4902 - val_loss: 3.1204 - val_accuracy: 0.2376\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.5160 - accuracy: 0.5112 - val_loss: 3.1968 - val_accuracy: 0.2308\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.4437 - accuracy: 0.5361 - val_loss: 3.2154 - val_accuracy: 0.2376\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.3954 - accuracy: 0.5519 - val_loss: 3.2520 - val_accuracy: 0.2579\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.3396 - accuracy: 0.5658 - val_loss: 3.3232 - val_accuracy: 0.2511\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.2543 - accuracy: 0.6037 - val_loss: 3.3089 - val_accuracy: 0.2545\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.1923 - accuracy: 0.6133 - val_loss: 3.4610 - val_accuracy: 0.2613\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.1461 - accuracy: 0.6300 - val_loss: 3.4149 - val_accuracy: 0.2534\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.0829 - accuracy: 0.6605 - val_loss: 3.6008 - val_accuracy: 0.2568\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.0328 - accuracy: 0.6662 - val_loss: 3.5633 - val_accuracy: 0.2624\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.9871 - accuracy: 0.6798 - val_loss: 3.6400 - val_accuracy: 0.2489\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.9403 - accuracy: 0.6996 - val_loss: 3.7069 - val_accuracy: 0.2670\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.8736 - accuracy: 0.7216 - val_loss: 3.7589 - val_accuracy: 0.2647\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.8255 - accuracy: 0.7259 - val_loss: 3.8136 - val_accuracy: 0.2715\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.7918 - accuracy: 0.7508 - val_loss: 3.9465 - val_accuracy: 0.2579\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7660 - accuracy: 0.7477 - val_loss: 3.9243 - val_accuracy: 0.2726\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.6787 - accuracy: 0.7822 - val_loss: 4.0576 - val_accuracy: 0.2738\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.6310 - accuracy: 0.8025 - val_loss: 4.0111 - val_accuracy: 0.2919\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.6298 - accuracy: 0.7935 - val_loss: 4.2076 - val_accuracy: 0.2692\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.5555 - accuracy: 0.8263 - val_loss: 4.1337 - val_accuracy: 0.2749\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.5275 - accuracy: 0.8306 - val_loss: 4.2626 - val_accuracy: 0.2681\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.5200 - accuracy: 0.8283 - val_loss: 4.3470 - val_accuracy: 0.2477\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.5003 - accuracy: 0.8354 - val_loss: 4.3705 - val_accuracy: 0.2738\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.4552 - accuracy: 0.8560 - val_loss: 4.3876 - val_accuracy: 0.2975\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.4533 - accuracy: 0.8546 - val_loss: 4.3186 - val_accuracy: 0.2681\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.4264 - accuracy: 0.8696 - val_loss: 4.5053 - val_accuracy: 0.2602\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.4117 - accuracy: 0.8673 - val_loss: 4.3938 - val_accuracy: 0.2738\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3938 - accuracy: 0.8752 - val_loss: 4.5518 - val_accuracy: 0.2613\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.3580 - accuracy: 0.8902 - val_loss: 4.6650 - val_accuracy: 0.2602\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3442 - accuracy: 0.8914 - val_loss: 4.6233 - val_accuracy: 0.2738\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.3369 - accuracy: 0.8965 - val_loss: 4.6549 - val_accuracy: 0.2794\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.3166 - accuracy: 0.9030 - val_loss: 4.7030 - val_accuracy: 0.2624\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.3001 - accuracy: 0.9050 - val_loss: 4.7576 - val_accuracy: 0.2670\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2895 - accuracy: 0.9143 - val_loss: 4.7766 - val_accuracy: 0.2602\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2992 - accuracy: 0.9103 - val_loss: 4.8930 - val_accuracy: 0.2805\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2530 - accuracy: 0.9256 - val_loss: 4.8981 - val_accuracy: 0.2862\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2421 - accuracy: 0.9296 - val_loss: 4.9794 - val_accuracy: 0.2692\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.2357 - accuracy: 0.9250 - val_loss: 4.9660 - val_accuracy: 0.2670\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2145 - accuracy: 0.9352 - val_loss: 4.9131 - val_accuracy: 0.2670\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.2274 - accuracy: 0.9332 - val_loss: 5.0974 - val_accuracy: 0.2873\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.2006 - accuracy: 0.9414 - val_loss: 5.0353 - val_accuracy: 0.2704\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.2001 - accuracy: 0.9378 - val_loss: 5.0341 - val_accuracy: 0.2500\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2071 - accuracy: 0.9372 - val_loss: 5.0155 - val_accuracy: 0.2964\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.2019 - accuracy: 0.9412 - val_loss: 5.1157 - val_accuracy: 0.2851\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.2133 - accuracy: 0.9344 - val_loss: 5.1572 - val_accuracy: 0.2624\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1969 - accuracy: 0.9400 - val_loss: 5.1399 - val_accuracy: 0.2726\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.1670 - accuracy: 0.9474 - val_loss: 5.2388 - val_accuracy: 0.2885\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1749 - accuracy: 0.9468 - val_loss: 5.2019 - val_accuracy: 0.2715\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1760 - accuracy: 0.9443 - val_loss: 5.2453 - val_accuracy: 0.2647\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1807 - accuracy: 0.9477 - val_loss: 5.3292 - val_accuracy: 0.2692\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.2046 - accuracy: 0.9344 - val_loss: 5.3662 - val_accuracy: 0.2624\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.2025 - accuracy: 0.9364 - val_loss: 5.1737 - val_accuracy: 0.2647\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.1876 - accuracy: 0.9434 - val_loss: 5.2433 - val_accuracy: 0.2658\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.1565 - accuracy: 0.9525 - val_loss: 5.3560 - val_accuracy: 0.2511\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1482 - accuracy: 0.9612 - val_loss: 5.3674 - val_accuracy: 0.2636\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1348 - accuracy: 0.9627 - val_loss: 5.4812 - val_accuracy: 0.2738\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.1245 - accuracy: 0.9629 - val_loss: 5.4730 - val_accuracy: 0.2658\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1355 - accuracy: 0.9584 - val_loss: 5.5088 - val_accuracy: 0.2568\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1309 - accuracy: 0.9638 - val_loss: 5.4719 - val_accuracy: 0.2896\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.1377 - accuracy: 0.9562 - val_loss: 5.5046 - val_accuracy: 0.2851\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1420 - accuracy: 0.9593 - val_loss: 5.5499 - val_accuracy: 0.2692\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1317 - accuracy: 0.9579 - val_loss: 5.6480 - val_accuracy: 0.2647\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1399 - accuracy: 0.9562 - val_loss: 5.4277 - val_accuracy: 0.2704\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1697 - accuracy: 0.9448 - val_loss: 5.5354 - val_accuracy: 0.2670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f311a4e2be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "model.fit(data_X, data_y, \n",
    "         epochs=100, \n",
    "         batch_size=128, \n",
    "         callbacks=[checkpoint_callback], \n",
    "         validation_split=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRVDjJWMyPOw"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNvw5K-uGxVl"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def generate(model, seed, n_vocab, int_to_char, temperature=1, num_gen=1000):\n",
    "    print (\"Seed:\")\n",
    "    for p in seed:\n",
    "        sys.stdout.write(int_to_char[np.argmax(p)])\n",
    "    print(\"\\n--------------------------------------------\\n\")\n",
    "    pattern = seed\n",
    "\n",
    "    # generate characters\n",
    "    for i in range(num_gen):\n",
    "        prediction = model.predict(pattern[None], verbose=0)\n",
    "\n",
    "        probabilities = prediction.flatten()\n",
    "        if temperature != 1:\n",
    "            # maybe not exactly right but close enough, and probably exactly right\n",
    "            probabilities = probabilities**(1.0/temperature) \n",
    "            probabilities /= np.sum(probabilities)\n",
    "\n",
    "        index = np.random.choice(n_vocab, p=probabilities)\n",
    "            \n",
    "        result = int_to_char[index]\n",
    "        sys.stdout.write(result)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        new_char_one_hot = np.zeros(n_vocab)\n",
    "        new_char_one_hot[index] = 1.0\n",
    "        pattern = np.append(pattern[1:], new_char_one_hot[None], axis=0)\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    gc.collect() # http://stackoverflow.com/questions/40560795/tensorflow-attributeerror-nonetype-object-has-no-attribute-tf-deletestatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19610,
     "status": "ok",
     "timestamp": 1587357857745,
     "user": {
      "displayName": "varada kolhatkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgQrcDFm59pZ859zTkQgrMPppBvkUHXzKN9D8_qxw=s64",
      "userId": "02873324325420823018"
     },
     "user_tz": 420
    },
    "id": "0zs7mCrmGxsa",
    "outputId": "fef0c127-3da3-4aab-952a-8e3ad2fa8e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "id played and it pleased \n",
      "--------------------------------------------\n",
      "\n",
      "the lord\n",
      "but you don't really care for music, do you?\n",
      "well it goes like this\n",
      "the fourth, the fifth, the minor fall and the major lift\n",
      "the baffled king composing hallelujah\n",
      "hallelujah\n",
      "helllujah\n",
      "hsssluaah wyas bow tillhw the bboolrc hin\n",
      "thd bofodl  ang termswiaig the lollls\n",
      "the shil hhee tas iing\n",
      "orgt hell bfrnn\n",
      "th be fon lon the sror win in toe belll) that stil clae ring\n",
      "forget your prffee toffering\n",
      "there is  acrccc, a akac ii eveeyhhin tter iir mrf\n",
      "fienht teeelisw wo si, ioney louctedd ago ai\n",
      "ia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pick random seed (one of two ways depending on primetext)\n",
    "import gc\n",
    "start = np.random.randint(0, n_examples)\n",
    "seed = data_X[start]\n",
    "generate(model, seed, n_vocab, idx2char, temperature=0.5, num_gen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7c28fdU_zrL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN/2EFrW2X5oqLfsQqtlvJE",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "lstm_text_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
