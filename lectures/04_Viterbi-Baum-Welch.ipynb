{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/575_banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 4: Decoding and Learning in HMMs\n",
    "\n",
    "UBC Master of Data Science program, 2022-23\n",
    "\n",
    "Instructor: Varada Kolhatkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture plan, imports, LO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Lecture plan \n",
    "\n",
    "- Recap and using `hmmlearn` (~5 mins)\n",
    "- T/F questions (~5 mins)\n",
    "- The Viterbi algorithm (~30)\n",
    "- Break (~5 mins)\n",
    "- T/F questions (~5 mins)\n",
    "- The backward algorithm (~10 mins)\n",
    "- (optional) Baum-Welch estimation (~10 mins)\n",
    "- Final comments and summary (~2 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes\n",
    "\n",
    "From this lesson you will be able to\n",
    "\n",
    "- Explain the general idea and purpose of the Viterbi algorithm.\n",
    "- Explain the three steps in the Viterbi algorithm and apply it given an HMM and an observation sequence.\n",
    "- Compute $\\delta_i(t)$ and $\\psi_i(t)$ for a given state $i$ at time step $t$. \n",
    "- Explain the general idea of the backward algorithm.\n",
    "- Compute $\\beta_i(t)$ for a given state $i$ at time step $t$. \n",
    "- Explain the purpose and the general idea of the Baum-Welch algorithm.\n",
    "- Use `hmmlearn` for liklihood, decoding, and HMM unsupervised training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“â“ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Select all of the following statements which are **True** (iClicker)\n",
    "\n",
    "- (A) In the forward algorithm we assume that the observation sequence $O$ and the model parameters are fixed and known. \n",
    "- (B) In the forward algorithm, in our notation, $\\alpha_{i}(t)$ represents the probability of being in state $i$ at time $t$ after seeing all the observations including the observation at time step $t$. \n",
    "- (C) In the forward algorithm $\\alpha_i(t)$ does not know anything about the future time steps after the time step $t$. \n",
    "- (D) We conclude the forward procedure by summing over the $\\alpha$ values at the last time step.\n",
    "- (E) To learn an HMM in a supervised fashion, there has to be a one-to-one correspondence between observations and hidden states in our training data (e.g., the observation _book_ should always map to the hidden state _noun_). \n",
    "- (F) In the lab when you call `score` on all trained models to predict the label of the given utterance, it's likely using the forward algorithm under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 4.1: V's Solutions!\n",
    ":class: tip, dropdown\n",
    "- (A) True\n",
    "- (B) True\n",
    "- (C) True\n",
    "- (D) True\n",
    "- (E) False\n",
    "- (F) True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Lecture 3: \n",
    "- The forward procedure using dynamic programming needs only $\\approx 2n^2T$ multiplications compared to the $\\approx(2T)n^T$ multiplications with the naive approach!! \n",
    "- Why? Discuss with your neighbour.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Hidden Markov models (HMMs) model sequential data with latent factors.\n",
    "- There are tons of applications associated with them and they are more realistic than Markov models. \n",
    "\n",
    "![](img/HMM_example.png)\n",
    "\n",
    "<!-- <img src=\"img/HMM_example.png\" height=\"500\" width=\"500\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### HMM ingredients\n",
    "- Hidden states (e.g., Happy, Sad)\n",
    "- Output alphabet or output symbols or observations (e.g., learn, study, cry, facebook)\n",
    "- Discrete initial state probability distribution\n",
    "- Transition probabilities\n",
    "- Emission probabilities    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fundamental questions for HMMs \n",
    "\n",
    "- Three fundamental questions for HMMs: \n",
    "    - likelihood\n",
    "    - decoding\n",
    "    - parameter learning \n",
    "- The forward algorithm is a dynamic programming algorithm to efficiently calculate the probability of an observation sequence given an HMM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: The forward algorithm\n",
    "- The forward algorithm computes likelihood of a given observation sequence: $P(O;\\theta)$. \n",
    "- For each state $i$, we calculated $\\alpha_i(0), \\alpha_i(1), \\alpha_i(2), ...\\alpha_i(t)$, which represent the probabilities of being in state $i$ at times $t$ knowing all the observations which came before and at time $t$. \n",
    "- The trellis was computed left to right and top to bottom.\n",
    "- The forward algorithm stores the probabilities of all possible 1-state sequences (from the start), to store all possible 2-state sequences (from the start), to store all possible 3-state sequences (from the start) and so on. \n",
    "\n",
    "![](img/hmm_alpha_values.png)\n",
    "\n",
    "- Sum over all possible final states:\n",
    "  * $P(O;\\theta) = \\sum\\limits_{i=1}^{n}\\alpha_i(T-1)$\n",
    "  * $P(E,L,F,C) = \\alpha_ğŸ™‚(3) + \\alpha_ğŸ˜”(3) = 0.00023 + 0.00207 = 0.0023$ \n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/hmm_alpha_values.png\" height=\"500\" width=\"500\">  -->\n",
    "<!-- </center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's calculate the likelihood of observing an observation sequence given a particular set of model parameters $\\theta$. \n",
    "using `hmmlearn`. \n",
    "\n",
    "![](img/HMM_example.png)\n",
    "\n",
    "<!-- <img src=\"img/HMM_example.png\" height=\"600\" width=\"600\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the code below successfully, you need install `networkx` and `graphviz`. \n",
    "\n",
    "```\n",
    "conda install -c conda-forge graphviz\n",
    "conda install -c conda-forge python-graphviz\n",
    "conda install -c anaconda networkx\n",
    "conda install -c anaconda pydot\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "# Initializing an HMM\n",
    "states = [\"Happy\", \"Sad\"]\n",
    "n_states = len(states)\n",
    "\n",
    "symbols = [\"Learn\", \"Eat\", \"Cry\", \"Facebook\"]\n",
    "n_observations = len(symbols)\n",
    "\n",
    "model = hmm.CategoricalHMM(\n",
    "    n_components=n_states, random_state=42\n",
    ")  # for discrete observations\n",
    "\n",
    "# Set the initial state probabilities\n",
    "model.startprob_ = np.array([0.8, 0.2])\n",
    "\n",
    "# Set the transition matrix\n",
    "model.transmat_ = np.array([[0.7, 0.3], [0.4, 0.6]])\n",
    "\n",
    "# Set the emission probabilities of shape (n_components, n_symbols)\n",
    "model.emissionprob_ = np.array([[0.7, 0.2, 0.1, 0.0], [0.1, 0.1, 0.6, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def visualize_hmm(model, states=[\"s0\", \"s1\"]):\n",
    "    transmat_df = pd.DataFrame(model.transmat_, index=states, columns=states)\n",
    "\n",
    "    # Get edges and their weights from the transition matrix\n",
    "    edges = {}\n",
    "    for col in transmat_df.columns:\n",
    "        for idx in transmat_df.index:\n",
    "            val = round(transmat_df.loc[idx, col], 3)\n",
    "            if val > 0:\n",
    "                edges[(idx, col)] = val\n",
    "\n",
    "    # Create graph\n",
    "    graph = nx.MultiDiGraph()\n",
    "    graph.add_nodes_from(states)  # nodes correspond to states\n",
    "    print(f\"Nodes:\\n{graph.nodes()}\\n\")\n",
    "\n",
    "    # edges represent transition probabilities\n",
    "    for k, v in edges.items():\n",
    "        tmp_source, tmp_dest = k[0], k[1]\n",
    "        graph.add_edge(tmp_source, tmp_dest, weight=v, label=v)\n",
    "    pos = nx.drawing.nx_pydot.graphviz_layout(graph, prog=\"dot\")\n",
    "    # nx.draw_networkx(graph, pos)\n",
    "\n",
    "    edge_labels = {(n1, n2): d[\"label\"] for n1, n2, d in graph.edges(data=True)}\n",
    "    # nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels)\n",
    "    dot_filename = \"test.dot\"\n",
    "    nx.drawing.nx_pydot.write_dot(graph, dot_filename)\n",
    "    with open(dot_filename) as f:\n",
    "        dot_graph = f.read()\n",
    "    return graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:\n",
      "['happy', 'sad']\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"109pt\" height=\"131pt\"\n",
       " viewBox=\"0.00 0.00 108.99 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 104.99,-127 104.99,4 -4,4\"/>\n",
       "<!-- happy -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>happy</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"32.5\" cy=\"-105\" rx=\"32.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.5\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">happy</text>\n",
       "</g>\n",
       "<!-- happy&#45;&gt;happy -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>happy&#45;&gt;happy</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.06,-113.12C73.49,-113.49 82.99,-110.78 82.99,-105 82.99,-101.3 79.09,-98.86 73.29,-97.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.8,-94.2 63.57,-96.98 73.3,-101.19 73.8,-94.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"91.99\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.7</text>\n",
       "</g>\n",
       "<!-- sad -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sad</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"32.5\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">sad</text>\n",
       "</g>\n",
       "<!-- happy&#45;&gt;sad -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>happy&#45;&gt;sad</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M21.06,-88.09C15.47,-78.41 10.53,-65.7 13.5,-54 14.27,-50.96 15.36,-47.91 16.64,-44.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"19.75,-46.54 21.14,-36.04 13.5,-43.38 19.75,-46.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"22.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.3</text>\n",
       "</g>\n",
       "<!-- sad&#45;&gt;happy -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sad&#45;&gt;happy</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M32.5,-36.47C32.5,-47.74 32.5,-62.67 32.5,-75.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"29,-75.29 32.5,-85.29 36,-75.29 29,-75.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"41.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.4</text>\n",
       "</g>\n",
       "<!-- sad&#45;&gt;sad -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>sad&#45;&gt;sad</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.03,-26.03C68,-26.79 77.5,-24.12 77.5,-18 77.5,-14.18 73.79,-11.7 68.33,-10.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.71,-7.08 58.54,-10.05 68.34,-14.07 68.71,-7.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.6</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x17712d240>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_hmm(model, states=[\"happy\", \"sad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission probabilities: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learn</th>\n",
       "      <th>Eat</th>\n",
       "      <th>Cry</th>\n",
       "      <th>Facebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Happy</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sad</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Learn  Eat  Cry  Facebook\n",
       "Happy    0.7  0.2  0.1       0.0\n",
       "Sad      0.1  0.1  0.6       0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Emission probabilities: \")\n",
    "pd.DataFrame(data=model.emissionprob_, columns=symbols, index=states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In the last lecture we talked about how to calculate probability of an observation sequence efficiently using the forward algorithm. \n",
    "- We can use the `.score` method of the hmm model in `hmmlearn` to calculate log probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_seq = np.array([[1], [0], [3], [2]])\n",
    "label_obs_seq = map(lambda x: symbols[x], obs_seq.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of sequence ['Eat', 'Learn', 'Facebook', 'Cry'] is -6.073108536148493 \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Log probability of sequence %s is %s \"\n",
    "    % (list(label_obs_seq), model.score(obs_seq))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What else can we do with HMMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Recall the three fundamental questions for an HMM. \n",
    "\n",
    "#### Likelihood\n",
    "Given a model with parameters $\\theta = <\\pi, A, B>$, how do we efficiently compute the likelihood of a particular observation sequence $O$?\n",
    "#### Decoding\n",
    "Given an observation sequence $O$ and a model $\\theta$ how do we choose a state sequence $Q={q_0, q_1, \\dots q_T}$ that best explains the observation sequence?\n",
    "#### Learning\n",
    "Training: Given a large observation sequence $O$ how do we choose the best parameters $\\theta$ that explain the data $O$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decoding \n",
    "\n",
    "- Let's try out decoding on our toy example before learning how it's done. \n",
    "- Let's calculate the most likely hidden state sequence given the observation sequence: Eat, Learn, Facebook, Cry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_state_seq(model, observation_seq, states=states, symbols=symbols):\n",
    "    logprob, state_seq = model.decode(observation_seq, algorithm=\"viterbi\")\n",
    "    o_seq = map(lambda x: symbols[x], observation_seq.T[0])\n",
    "    s_seq = map(lambda x: states[x], state_seq)\n",
    "    print(\"log probability of state sequence: \", logprob)\n",
    "    return pd.DataFrame(data=s_seq, index=o_seq, columns=[\"state sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability of state sequence:  -6.3809933159177925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eat</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learn</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook</th>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cry</th>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state sequence\n",
       "Eat               Happy\n",
       "Learn             Happy\n",
       "Facebook            Sad\n",
       "Cry                 Sad"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoding example\n",
    "toy_seq = np.array([[1], [0], [3], [2]])\n",
    "get_state_seq(model, toy_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning\n",
    "\n",
    "- In the last lecture, we saw supervised learning of HMMs where we knew the mapping between observation sequences and hidden state sequences.\n",
    "- We used MLE to get transition probabilities and the emission probabilities. \n",
    "- In many cases, the mapping between hidden states and observations is unknown and so we can't use MLE. \n",
    "- How to deal with the incomplete data?\n",
    "    - Use unsupervised learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decoding: The Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Given an observation sequence $O$ and a model $\\theta$ how do we choose a state sequence $Q={q_0, q_1, \\dots q_T}$ that best explains the observation sequence?\n",
    "- Purpose: finding what's most likely going on under the hood. \n",
    "- For example: It tells us the most likely part-of-speech tags given an English sentence.\n",
    "\n",
    "<blockquote>\n",
    "Will/MD the/DT chair/NN chair/VB the/DT meeting/NN from/IN that/DT chair/NN?\n",
    "</blockquote>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Can we use the forward algorithm for decoding?\n",
    "\n",
    "If we want to pick an optimal state sequence which maximizes the probability of the observation sequence, how about picking the state with maximum $\\alpha$ value at each time step? \n",
    "\n",
    "![](img/hmm_alpha_values.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/hmm_alpha_values.png\" height=\"500\" width=\"500\">  -->\n",
    "<!-- </center> -->\n",
    "\n",
    "If we pick the most probable state at each time step based on the $\\alpha$ values, it might not end up as the best state sequence because it might be possible that the transition between two highly probable states in a sequence is very unlikely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### The Viterbi algorithm: Choosing $Q={q_{0:T}}$\n",
    "\n",
    "- Given an HMM, choose the state sequence that maximizes the probability of the output sequence.  \n",
    " * $Q^* = \\arg \\max\\limits_Q P(O,Q;\\theta)$, \n",
    " * $P(O,Q;\\theta) = \\pi_{q_0}b_{q_0}(o_0) \\prod\\limits_{t=1}^{T}a_{q_{t-1}}a_{q_t}b_{q_t}(o_t)$\n",
    " \n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Viterbi algorithm: Choosing $Q={q_{0:T}}$\n",
    "\n",
    "- Dynamic programming algorithm.\n",
    "- We use a different kind of trellis.\n",
    "- Want: Given an HMM, choose the state sequence that maximizes the probability of the output sequence.  \n",
    " * $Q^* = \\arg \\max\\limits_Q P(O,Q;\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Viterbi algorithm: Choosing $Q={q_{0:T}}$\n",
    "\n",
    "- We store $\\delta$ and $\\psi$ values at each node in the trellis\n",
    "\n",
    "- $\\delta_i(t)$ = the probability of the most probable path leading to the trellis node at state $i$ and time $t$\n",
    "- $\\psi_i(t) =$ The best possible previous state if I am in state $i$ at time $t$. \n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi: Initialization\n",
    "- Initialize with $\\delta_i(0) = \\pi_i b_i(o_0)$ for all states\n",
    "    - $\\delta_ğŸ™‚(0) = \\pi_ğŸ™‚ b_ğŸ™‚(E) = 0.8 \\times 0.2 = 0.16$\n",
    "    - $\\delta_ğŸ˜”(0) = \\pi_ğŸ˜” b_ğŸ˜”(E) = 0.2 \\times 0.1 = 0.02$\n",
    "    \n",
    "- Initialize with $\\psi_i(0) = 0 $, for all states   \n",
    "    - $\\psi_ğŸ™‚(0) = 0, \\psi_ğŸ˜”(0) = 0$\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi: Induction\n",
    "\n",
    "The best path $\\delta_t$ to state $j$ at time $t$ depends on the best path to each\n",
    "possible previous state $\\delta_i(t-1)$ and their transitions to $j$ ($a_{ij}$). \n",
    "\n",
    "- $\\delta_j(t) = \\max\\limits_i \\{\\delta_i(t-1)a_{ij}\\} b_j(o_t)$\n",
    "- $\\psi_j(t) = \\arg \\max\\limits_i \\{\\delta_i(t-1)a_{ij}\\} $\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"800\" width=\"800\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi induction: $\\delta$ and $\\psi$ intuition\n",
    "\n",
    "![](img/viterbi_explanation.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/viterbi_explanation.png\" height=\"150\" width=\"150\">  -->\n",
    "<!-- </center> -->\n",
    "\n",
    "- There are two possible paths to state ğŸ™‚ at $T = 1$. Which is the best one? \n",
    "- $\\delta_ğŸ™‚(1) = \\max \\begin{Bmatrix} \\delta_ğŸ™‚(0) \\times a_{ğŸ™‚ğŸ™‚},\\\\ \\delta_ğŸ˜”(0) \\times a_{ğŸ˜”ğŸ™‚}\\end{Bmatrix}  \\times b_ğŸ™‚(L)$\n",
    "- First take the max between $\\delta_ğŸ™‚(0) \\times a_{ğŸ™‚ğŸ™‚}$ and $\\delta_ğŸ˜”(0) \\times a_{ğŸ˜”ğŸ™‚}$ and then multiply the max by $b_ğŸ™‚(L)$.   \n",
    "    \n",
    "- $\\psi_ğŸ™‚(1)$ = the state at $T=0$ from where the path to ğŸ™‚ at $T=1$ was the best one.     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi:  notation\n",
    "\n",
    "- **Note that we use parentheses to show two quantities for taking the max. (Not the best notation but I have seen it being used in this context.)**  \n",
    "- $\\delta_ğŸ™‚(1) = \\max \\begin{Bmatrix} \\delta_ğŸ™‚(0) \\times a_{ğŸ™‚ğŸ™‚},\\\\ \\delta_ğŸ˜”(0) \\times a_{ğŸ˜”ğŸ™‚}\\end{Bmatrix}  \\times b_ğŸ™‚(L)$\n",
    "- First take the max between $\\delta_ğŸ™‚(0) \\times a_{ğŸ™‚ğŸ™‚}$ and $\\delta_ğŸ˜”(0) \\times a_{ğŸ˜”ğŸ™‚}$ and then multiply the max by $b_ğŸ™‚(L)$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Viterbi: Induction (T = 1)\n",
    "\n",
    "$\\delta$ and $\\psi$ at state ğŸ™‚ and T = 1\n",
    "- $\\delta_{ğŸ™‚}(1) = \\max\\limits_i \\{\\delta_i(0)a_{ij}\\} b_j(o_t) = \n",
    "\\max \\begin{Bmatrix} 0.16 \\times 0.7, \\\\ 0.02 \\times 0.4\\end{Bmatrix} \\times 0.7 = 0.0784$\n",
    "- $\\psi_{ğŸ™‚}(1) = \\arg \\max\\limits_i \\{\\delta_i(0)a_{ij}\\} = ğŸ™‚$\n",
    "\n",
    "$\\delta$ and $\\psi$ at state ğŸ˜” and T = 1\n",
    "- $\\delta_{ğŸ˜”}(1) = \\max\\limits_i \\{\\delta_i(0)a_{ij}\\} b_j(o_t) =  \\max \\begin{Bmatrix} 0.16 \\times 0.3, \\\\ 0.02 \\times 0.6\\end{Bmatrix} \\times 0.1 = 0.0048$\n",
    "- $\\psi_{ğŸ˜”}(1) = \\arg \\max\\limits_i \\{\\delta_i(0)a_{ij}\\} = ğŸ™‚$\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"800\" width=\"800\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi: Induction (T = 1)\n",
    "\n",
    "$\\delta$ and $\\psi$ at state ğŸ™‚ and T = 1\n",
    "- $\\delta_{ğŸ™‚}(1) = \\max \\begin{Bmatrix} \\delta_ğŸ™‚(0) \\times a_{ğŸ™‚ğŸ™‚}, \\\\ \\delta_ğŸ˜”(0) \\times a_{ğŸ˜”ğŸ™‚}\\end{Bmatrix}  \\times b_ğŸ™‚(L) = \n",
    "\\max \\begin{Bmatrix} 0.16 \\times 0.7, \\\\ 0.02 \\times 0.4\\end{Bmatrix} \\times 0.7 = 0.0784$\n",
    "- $\\psi_{ğŸ™‚}(1)  = ğŸ™‚$\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"800\" width=\"800\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi: Induction (T = 1)\n",
    "\n",
    "$\\delta$ and $\\psi$ at state ğŸ˜” and T = 1\n",
    "- $\\delta_{ğŸ˜”}(1) = \\max\\limits_i \\{\\delta_i(0)a_{ij}\\} b_j(o_t) =  \\max \\begin{Bmatrix} 0.16 \\times 0.3 ,\\\\ 0.02 \\times 0.6\\end{Bmatrix} \\times 0.1 = 0.0048$\n",
    "- $\\psi_{ğŸ˜”}(1) = \\arg \\max\\limits_i \\{\\delta_i(0)a_{ij}\\} = ğŸ™‚$\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"800\" width=\"800\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi: Induction (T = 2)\n",
    "\n",
    "- $\\delta$ and $\\psi$ at state ğŸ™‚ and T = 2\n",
    "    - $\\delta_{ğŸ™‚}(2) = \\max\\limits_i \\{\\delta_i(1)a_{ij}\\} b_j(o_t) =  \\max \\begin{Bmatrix} 0.784 \\times 0.7, \\\\ 0.0048 \\times 0.4 \\end{Bmatrix}\\times 0 = 0\n",
    "$\n",
    "    - $\\psi_{ğŸ™‚}(2) = \\arg \\max\\limits_i \\{\\delta_i(1)a_{ij}\\} = ğŸ™‚$\n",
    "\n",
    "- $\\delta$ and $\\psi$ at state ğŸ˜” and T = 2\n",
    "    - $\\delta_{ğŸ˜”}(2) = \\max\\limits_i \\{\\delta_i(1)a_{ij}\\} b_j(o_t) =  \\max \\begin{Bmatrix} 0.784 \\times 0.3, \\\\ 0.0048 \\times 0.6 \\end{Bmatrix}\\times 0.2 = 4.704 \\times 10^{-3}$\n",
    "    - $\\psi_{ğŸ˜”}(2) = \\arg \\max\\limits_i \\{\\delta_i(1)a_{ij}\\} = ğŸ™‚$\n",
    "\n",
    "<br>\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"400\" width=\"400\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Viterbi: Induction (T = 3)\n",
    "\n",
    "- $\\delta$ and $\\psi$ at state ğŸ™‚ and T = 3\n",
    "    - $\\delta_{ğŸ™‚}(3) = \\max\\limits_i \\{\\delta_i(2)a_{ij}\\} b_j(o_t) = \\max \\begin{Bmatrix} 0 \\times 0.7, \\\\ 4.704 \\times 10^{-3} \\times 0.4 \\end{Bmatrix} \\times 0.1 = 1.88\\times10^{-4}\n",
    "$\n",
    "    - $\\psi_{ğŸ™‚}(3) = \\arg \\max\\limits_i \\{\\delta_i(2)a_{ij}\\} = ğŸ˜”$\n",
    "\n",
    "- $\\delta$ and $\\psi$ at state ğŸ˜” and T = 3\n",
    "    - $\\delta_{ğŸ˜”}(3) = \\max\\limits_i \\{\\delta_i(2)a_{ij}\\} b_j(o_t) = \\max \\begin{Bmatrix} 0 \\times 0.3, \\\\ 4.704 \\times 10^{-3} \\times 0.6 \\end{Bmatrix} \\times 0.6 = 1.69 \\times 10^{-3}$\n",
    "    - $\\psi_{ğŸ˜”}(3) = \\arg \\max\\limits_i \\{\\delta_i(2)a_{ij}\\} = ğŸ˜”$\n",
    "\n",
    "<br>\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"400\" width=\"400\">  -->\n",
    "<!-- </center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi conclusion\n",
    "- Choose the best final state: $q_t^* = \\arg \\max\\limits_i \\delta_i(t)$\n",
    "- Recursively choose the best previous state: $q_{t-1}^* = \\psi_{q_t^*}(t)$\n",
    "    - The most likely state sequence for the observation sequence ELFC is ğŸ™‚ğŸ™‚ğŸ˜”ğŸ˜”.\n",
    "- The probability of the state sequence is the probability of $q_t^*$\n",
    "    - $P(ğŸ™‚ğŸ™‚ğŸ˜”ğŸ˜”) = 1.69 \\times 10^{-3}$    \n",
    "    \n",
    "![](img/HMM_viterbi_conclusion.png)\n",
    "\n",
    "<!-- <img src=\"img/HMM_viterbi_conclusion.png\" height=\"600\" width=\"600\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi on our toy HMM \n",
    "\n",
    "![](img/HMM_example.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example.png\" height=\"500\" width=\"500\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Viterbi with [ `hmmlearn`](https://hmmlearn.readthedocs.io)\n",
    "\n",
    "Let's get the optimal state sequence using Viterbi in our toy example.  \n",
    "- We assume that we already have the model, i.e., transition probabilities, emission probabilities, and initial state probabilities. \n",
    "- Our goal is to efficiently find the best state sequence for the given observation sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Initializing an HMM\n",
    "states = [\"Happy\", \"Sad\"]\n",
    "n_states = len(states)\n",
    "\n",
    "observations = [\"Learn\", \"Eat\", \"Cry\", \"Facebook\"]\n",
    "n_observations = len(observations)\n",
    "\n",
    "# Since we've discrete observations, we'll use `MultinomialHMM`\n",
    "model = hmm.CategoricalHMM(n_components=n_states)\n",
    "\n",
    "# Set the initial state probabilities\n",
    "model.startprob_ = np.array([0.8, 0.2])\n",
    "\n",
    "# Set the transition matrix\n",
    "model.transmat_ = np.array([[0.7, 0.3], [0.4, 0.6]])\n",
    "\n",
    "# Set the emission probabilities of shape (n_components, n_symbols)\n",
    "model.emissionprob_ = np.array([[0.7, 0.2, 0.1, 0.0], [0.1, 0.1, 0.6, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_state_seq(model, observation_seq, states=states, symbols=symbols):\n",
    "    logprob, state_seq = model.decode(observation_seq, algorithm=\"viterbi\")\n",
    "    o_seq = map(lambda x: symbols[x], observation_seq.T[0])\n",
    "    s_seq = map(lambda x: states[x], state_seq)\n",
    "    print(\"log probability of state sequence: \", logprob)\n",
    "    return pd.DataFrame(data=s_seq, index=o_seq, columns=[\"state sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability of state sequence:  -6.3809933159177925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eat</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learn</th>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook</th>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cry</th>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state sequence\n",
       "Eat               Happy\n",
       "Learn             Happy\n",
       "Facebook            Sad\n",
       "Cry                 Sad"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoding example\n",
    "toy_seq = np.array([[1], [0], [3], [2]])\n",
    "get_state_seq(model, toy_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi final comments\n",
    "\n",
    "- This is how you find the best state sequence that explains the observation sequence using the Viterbi algorithm!   \n",
    "- Much faster than the brute force approach of considering all possible state combinations, calculating probabilities for each of them and taking the one resulting in maximum probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## â“â“ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Select all of the following statements which are **True** (iClicker)\n",
    "\n",
    "- (A) You can pass sequences of different lengths when training HMMs.  \n",
    "- (B) In Viterbi, $\\delta_i(t)$ is the probability of the best path (i.e., the path with highest probability) which accounts for the first $t$ observations and ending at state $i$.\n",
    "- (C) In Viterbi, suppose at $t-1$, state $i$ has the highest $\\delta_i(t-1)$ among all states. Then at time step $t$, the path from $i$ at $t-1$ is going to give us the highest $\\delta_j(t)$ for all states $j$ at time $t$.\n",
    "- (D) In Viterbi, the $\\psi_j(t)$ keeps track of the state from the previous time step which results in highest $\\delta_i(t-1)a_{ij}$ so that we can keep track of where we came from and we can recreate the path. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 4.2: V's Solutions!\n",
    ":class: tip, dropdown\n",
    "- (A) True\n",
    "- (B) True\n",
    "- (C) False. This will also depend upon the transition probabilities between states.  \n",
    "- (D) True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The backward algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In the last lecture we talked about supervised training of HMMs where we assumed that we had mapping between observation sequences and hidden state sequences. \n",
    "- In real life we rarely have such mapping available.  \n",
    "- For example, you can imagine how much manual effort it would be to come up with gold part-of-speech tag sequences on a large enough sample of text data, say Wikipedia, so that we have enough training data in order to learn initial state probabilities, transition probabilities, and emission probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question we want to answer  \n",
    "\n",
    "Given a large observation sequence (or a set of observation sequences) $O$ for training, but **not** the state sequence, how do we choose the \"best\" parameters $\\theta$ that explain the data $O$? \n",
    "\n",
    "We want our parameters $\\theta$ to be set so that the available training data is maximally likely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we do it? \n",
    "\n",
    "- Forward-backward algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall: Forward algorithm goal\n",
    "\n",
    "- Compute likelihood\n",
    "\n",
    "Given a model with parameters $\\theta = <\\pi, T, B>$, how do we efficiently compute the likelihood of a particular observation sequence $O$?\n",
    "\n",
    "- Example: What's the probability of the sequence below? \n",
    "\n",
    "![](img/HMM_example_activity_seq.png)\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_activity_seq.png\" height=\"400\" width=\"400\">     -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The forward algorithm\n",
    "\n",
    "Three steps of the forward algorithm. \n",
    "\n",
    "- Initialization: Compute the $\\alpha$ values for nodes in the first column of the trellis $(t = 0)$.\n",
    "- Induction: Iteratively compute the $\\alpha$ values for nodes in the rest of the trellis $(1 \\leq t < T)$.\n",
    "- Conclusion: Sum over the $\\alpha$ values for nodes in the last column of the trellis $(t = T)$.\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"800\" width=\"800\">  -->\n",
    "<!-- </center>     -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The forward algorithm: conclusion\n",
    "\n",
    "- Sum over all possible final states:\n",
    "  * $P(O;\\theta) = \\sum\\limits_{i=1}^{n}\\alpha_i(T-1)$\n",
    "  * $P(E,L,F,C) = \\alpha_ğŸ™‚(3) + \\alpha_ğŸ˜”(3) = 0.00023 + 0.00207 = 0.0023$ \n",
    "\n",
    "![](img/hmm_alpha_values.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/hmm_alpha_values.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What are we doing in the forward algorithm?\n",
    "\n",
    "- In forward algorithm the point is to compute $P(O;\\theta)$. \n",
    "- For each state $i$, we calculated $\\alpha_i(0), \\alpha_i(1), \\alpha_i(2), ...$\n",
    "- The trellis was computed left to right and top to bottom.\n",
    "- The forward algorithm stores the probabilities of all possible 1-state sequences (from the start), to store all possible 2-state sequences (from the start), to store all possible 3-state sequences (from the start) and so on. \n",
    "\n",
    "![](img/hmm_alpha_values.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/hmm_alpha_values.png\" height=\"500\" width=\"500\">  -->\n",
    "<!-- </center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The backward algorithm intuition\n",
    "\n",
    "- Less intuitively, we can also do that in reverse order, i.e., from  right to left and top to bottom. \n",
    "- We'll still deal with the same observation sequence which evolves forward in time but we will store temporary results in the backward direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The backward algorithm intuition\n",
    "\n",
    "- In the $i^{th}$ node of the trellis at time $t$, we store the probability of starting in state $i$ at time $t$ then observing everything that comes thereafter. \n",
    "$$\\beta_{i}(t) = P(b_{t+1:T-1})$$\n",
    "\n",
    "- The trellis is computed **right-to-left** and **top-to-bottom**. \n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The backward algorithm: steps\n",
    "Three steps of the backward procedure. \n",
    "\n",
    "- Initialization: Initialize $\\beta$ values for nodes in the last column of the trellis. \n",
    "$$\\beta_i(T-1) = 1$$\n",
    "- Induction: Iteratively compute the $\\beta$ values for nodes in the rest of the trellis $(1 \\leq t < T)$ as the probability of being in state $i$ at time $t$ and reading everything to follow.\n",
    "$$\\beta_i(t) = \\sum_{j=1}^N a_{ij}b_{j}(o_{t+1}) \\beta_j(t+1)$$\n",
    "- Conclusion: Sum over the $\\beta$ values for nodes in the first column of the trellis $(t = 0)$ (i.e., all initial states).\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"500\" width=\"500\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The backward algorithm: Initialization $\\beta_ğŸ™‚(3)$ and $\\beta_ğŸ˜”(3)$\n",
    "\n",
    "- Initialize the nodes in the last column of the trellis $(T = 3)$.\n",
    "    * $\\beta_ğŸ™‚(3) = 1.0$\n",
    "    * $\\beta_ğŸ˜”(3) = 1.0$    \n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"800\" width=\"800\">  -->\n",
    "<!-- </center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### The backward algorithm: Induction\n",
    "\n",
    "- Iteratively compute the nodes in the rest of the trellis $(1 \\leq t < T)$.\n",
    "-  To compute $\\beta_j(t)$ we can compute $\\beta_{i}(t+1)$ for all possible states $i$ and then use our knowledge of $a_{ij}$ and $b_j(o_{t+1})$ \n",
    "$$\\beta_i(t) = \\sum_{j=1}^N a_{ij}b_{j}(o_{t+1}) \\beta_j(t+1)$$\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"800\" width=\"800\">  -->\n",
    "<!-- </center>     -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The backward algorithm: Induction $\\beta_ğŸ™‚(2)$\n",
    "\n",
    "$$\\beta_i(t) = \\sum_{j=1}^N a_{ij}b_{j}(o_{t+1}) \\beta_j(t+1)$$\n",
    "\n",
    "- Probability of being at state ğŸ™‚ at $t=2$ and observing everything to follow.  \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\beta_ğŸ™‚(2) = & a_{ğŸ™‚ğŸ™‚}b_ğŸ™‚(C)\\beta_ğŸ™‚(3) + a_{ğŸ™‚ğŸ˜”}b_ğŸ˜”(C)\\beta_ğŸ˜”(3)\\\\\n",
    "             = & 0.7 \\times 0.1 \\times 1.0 + 0.3 \\times 0.6 \\times 1.0\\\\ \n",
    "             = & 0.25& \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center>     -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The backward algorithm: Induction $\\beta_ğŸ˜”(2)$\n",
    "\n",
    "$$\\beta_i(t) = \\sum_{j=1}^N a_{ij}b_{j}(o_{t+1}) \\beta_j(t+1)$$\n",
    "\n",
    "- Probability of being at state ğŸ˜” at $t=2$ and observing everything to follow.  \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\beta_ğŸ˜”(2) = & a_{ğŸ˜”ğŸ™‚}b_ğŸ™‚(C)\\beta_ğŸ™‚(3) + a_{ğŸ˜”ğŸ˜”}b_ğŸ˜”(C)\\beta_ğŸ˜”(3)\\\\\n",
    "             = & 0.4 \\times 0.1 \\times 1.0 + 0.6 \\times 0.6 \\times 1.0\\\\ \n",
    "             = & 0.4& \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center>     -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Carry out rest of the steps as home work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The backward algorithm: Conclusion\n",
    "\n",
    "- Sum over all possible initial states to get the probability of an observation sequence in the reverse direction. \n",
    "\n",
    "$$P(O;\\theta) = \\sum_{i=1}^{N} \\pi_i b_i(t)\\beta_i(0)$$\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"700\" width=\"700\">  -->\n",
    "<!-- </center>     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We're not doing this just for fun. \n",
    "- We are going to use it for unsupervised HMM training! \n",
    "- In general, we can combine $\\alpha$ and $\\beta$ at any point in time to represent the probability of an entire sequence.  \n",
    "- This is going to be vital for training of unsupervised HMMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baum-Welch (BW) algorithm (high-level idea)\n",
    "\n",
    "Given a large observation sequence (or a set of observation sequences) $O$ for training, but **not** the state sequence, how do we choose the \"best\" parameters $\\theta$ that explain the data $O$? \n",
    "\n",
    "We want our parameters $\\theta$ to be set so that the available training data is maximally likely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Can we use MLE?\n",
    "\n",
    "- If the training data contained state sequences, we could simply do maximum likelihood estimation, as we did in the last lecture. \n",
    "- But when we are only given observations, we **cannot** count the following: \n",
    "    -  How often we move from $q_{i-1}$ to $q_i$ normalized by how often we move from $q_{i-1}$ to anything: \n",
    "      $p(q_i|q_{i-1}) = \\frac{Count(q_{i-1} q_i)}{Count(q_{i-1} \\text{ANY STATE })}$\n",
    "    - What's the proportion of $q_i$ emitting the observation $o_i$ .   \n",
    "      $p(o_i|q_{i}) = \\frac{Count(o_i \\text{ and } q_i)}{Count(q_{i})}$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution: iterative unsupervised approach \n",
    "\n",
    "- Iterative approach. \n",
    "- We guess the parameters and iteratively update them. \n",
    "- Unsupervised HMM training is done using a combination of the forward and the backward algorithms.  \n",
    "- The idea is that we can combine $\\alpha$ and $\\beta$ at any point in time to represent the probability of an entire observation sequence.  \n",
    "- The forward algorithm computes the $\\alpha$ values, which represent the probability of being in a particular state at a particular time, given the observation sequence up to that time. \n",
    "- The backward algorithm computes the $\\beta$ values, which represent the probability of observing the rest of the sequence after that time.\n",
    "- We define $\\gamma_i(t)$, which represents the probability of being in state $i$ at time $t$ given the entire observation sequence $O$. We calculate it by combining $\\alpha$ and $\\beta$ values calculated by the forward and backward algorithms.  \n",
    "- We define another probability $\\xi_{ij}(t)$ of landing in state $s_i$ at time $t$ and transitioning to state $s_j$ at time $t+1$ regardless of the previous states and future states given the observations.     \n",
    "- These probabilities are used to compute the expected sufficient statistics\n",
    "    - the expected number of times each state is visited\n",
    "    - the expected number of times each transition is made, given the observation sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expectation maximization \n",
    "\n",
    "- We will start with a randomly initialized model. \n",
    "- We use the model to calculate new $\\alpha_i(t), \\beta_i(t), \\gamma_i(t), \\xi_{ij}(t)$. \n",
    "- We update the model.  \n",
    "- We can do this iteratively until convergence or stopping condition. \n",
    "\n",
    "![](img/em.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/em.png\" height=\"700\" width=\"700\">        -->\n",
    "<!-- </center>    -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [AppendixB](AppendixB-BaumWelch.ipynb) for more details on Baum Welch algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning of our toy problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we know how to do decoding and unsupervised learning of HMMs in Python, let's learn about how do they work. Let's try it out with `hmmlearn` before learning about the details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(42)\n",
    "n = 200\n",
    "t = 4000\n",
    "X, Z = model.sample(t)\n",
    "\n",
    "range_min=10\n",
    "range_max=30\n",
    "seqlens = [random.randint(range_min, range_max) for i in range(n)]\n",
    "seqlens[-1] += t - sum(seqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [1],\n",
       "       [2],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's train an unsupervised HMM on these sampled sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CategoricalHMM(n_components=2, random_state=RandomState(MT19937) at 0x178831D40)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalHMM</label><div class=\"sk-toggleable__content\"><pre>CategoricalHMM(n_components=2, random_state=RandomState(MT19937) at 0x178831D40)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CategoricalHMM(n_components=2, random_state=RandomState(MT19937) at 0x178831D40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states = 2\n",
    "unsup_model = hmm.CategoricalHMM(n_components=n_states, random_state=42)\n",
    "unsup_model.fit(X, seqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:\n",
      "['s0', 's1']\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"111pt\" height=\"131pt\"\n",
       " viewBox=\"0.00 0.00 111.49 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 107.49,-127 107.49,4 -4,4\"/>\n",
       "<!-- s0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>s0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27.49\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27.49\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">s0</text>\n",
       "</g>\n",
       "<!-- s0&#45;&gt;s0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>s0&#45;&gt;s0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.02,-113.03C62.99,-113.79 72.49,-111.12 72.49,-105 72.49,-101.18 68.78,-98.7 63.32,-97.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.7,-94.08 53.53,-97.05 63.33,-101.07 63.7,-94.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.99\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.904</text>\n",
       "</g>\n",
       "<!-- s1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>s1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27.49\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27.49\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">s1</text>\n",
       "</g>\n",
       "<!-- s0&#45;&gt;s1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>s0&#45;&gt;s1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M13.21,-89.2C8.53,-83.38 3.91,-76.33 1.49,-69 -1.49,-60.02 1.5,-50.69 6.36,-42.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"9.1,-44.73 12.07,-34.56 3.41,-40.67 9.1,-44.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"16.99\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.096</text>\n",
       "</g>\n",
       "<!-- s1&#45;&gt;s0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>s1&#45;&gt;s0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M30.65,-36.1C32.07,-45.75 33.26,-58.04 32.49,-69 32.33,-71.2 32.12,-73.48 31.87,-75.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"28.43,-75.09 30.61,-85.46 35.37,-76 28.43,-75.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.99\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.999</text>\n",
       "</g>\n",
       "<!-- s1&#45;&gt;s1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>s1&#45;&gt;s1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.02,-26.03C62.99,-26.79 72.49,-24.12 72.49,-18 72.49,-14.18 68.78,-11.7 63.32,-10.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.7,-7.08 53.53,-10.05 63.33,-14.07 63.7,-7.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.99\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.001</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x177362ad0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_hmm(unsup_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57694394, 0.42305606])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_model.startprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90435681, 0.09564319],\n",
       "       [0.99898179, 0.00101821]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_model.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44111394, 0.15318986, 0.3212576 , 0.0844386 ],\n",
       "       [0.47408228, 0.14890717, 0.28467173, 0.09233883]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_model.emissionprob_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it with our toy HMM\n",
    "\n",
    "![](img/HMM_example_trellis.png)\n",
    "\n",
    "<!-- <img src=\"img/HMM_example_trellis.png\" height=\"600\" width=\"600\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The model doesn't look very close to the real model from which we have sampled the sequences. \n",
    "- But it's unsupervised and with more data the probabilities would probably make more sense. \n",
    "- Also, note that it's an unsupervised model and it doesn't give you interpretation of the states. You have to do it on your own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final comments and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Hidden Markov Models (HMMs) provide a probabilistic framework to model sequences. \n",
    "- They are much more practical compared to Markov models and are widely used. \n",
    "- Speech recognition is a success story for HMMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Three fundamental questions for HMMs\n",
    "\n",
    "**Likelihood**: Given a model with parameters $\\theta = <\\pi, A, B>$, how do we efficiently compute the likelihood of a particular observation sequence $O$?\n",
    "\n",
    "**Decoding**\n",
    "Given an observation sequence $O$ and a model $\\theta$ how do we choose a state sequence $Q={q_0, q_1, \\dots q_T}$ that best explains the observation sequence?\n",
    "\n",
    "**Learning**\n",
    "Given a large observation sequence $O$ how do we choose the best parameters $\\theta$ that explain the data $O$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important ideas to know\n",
    "\n",
    "- The definition of an HMM\n",
    "- The conditional independence assumptions of an HMM\n",
    "- The purpose of the forward algorithm and the backward algorithm.\n",
    "    - How to compute $\\alpha_i(t)$ and $\\beta_i(t)$\n",
    "- The purpose of the Viterbi algorithm.\n",
    "    - How to compute $\\delta_i(t)$ and $\\psi_i(t)$\n",
    "- The purpose of the Baum-Welch algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Continuous HMMs\n",
    "\n",
    "- If the observations are drawn from a continuous space (e.g., speech), the probabilities must be continuous as well. \n",
    "- HMMs generalize to continuous probability distributions. \n",
    "- In the lab your observations are mfcc feature vectors for time frames which are continuous observations. \n",
    "- In `hmmlearn` you can use `GaussianHMM` or `GMMHMM` for continuous observations. \n",
    "\n",
    "![](img/continuous_hmms.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/continuous_hmms.png\" height=\"400\" width=\"400\">        -->\n",
    "<!-- </center>    -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important ideas to know \n",
    "\n",
    "Using `hmmlearn` \n",
    "- For unsupervised training of HMMs. \n",
    "- For likelihood (`model.score`)    \n",
    "- For decoding (`model.decode`)\n",
    "- For discrete observations (`MultinomialHMM`)\n",
    "- For continuous observations (`GaussianHMM` or `GMMHMM`)\n",
    "- For sequences with varying lengths.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some useful resources and links \n",
    "- [Frank Rudzicz's slides on HMM](http://www.cs.toronto.edu/~frank/csc401/lectures2020/5_HMMs.pdf) \n",
    "- [Andrew McCallum's slides on HMM](https://people.cs.umass.edu/~mccallum/courses/inlp2004a/lect10-hmm2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“â“ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Exercise 4.3: More practice questions\n",
    "\n",
    "Discuss the following questions with your neighbour. \n",
    "\n",
    "Consider the sentence below:\n",
    "<blockquote>\n",
    "    Will the chair chair the meeting from this chair ?\n",
    "</blockquote>\n",
    "\n",
    "and a simple part-of-speech tagset: \n",
    "<blockquote>\n",
    "{noun, verb, determiner, preposition, punctuation}\n",
    "</blockquote>    \n",
    "\n",
    "The table below shows the possible assignments for words and part-of-speech tags. The symbol `x` denotes that the word and part-of-speech tag combination is possible. For instance, the word _chair_ is unlikely to be used as a determiner and so we do not have an `x` there. \n",
    "\n",
    "|    <i></i>    | Will    | the     | chair   | chair   | the     | meeting  | from    | this    | chair   | ?       |\n",
    "| ------------- | :-----: | :-----: | :-----: | :-----: | :----:  | :------: | :-----: | :-----: | :-----: | :----:  |\n",
    "| noun          | x       | x       |  x      | x       | x       | x        | <i></i> | <i></i> | x       | <i></i> |\n",
    "| verb          | x       | <i></i> |  x      | x       | <i></i> | x        | <i></i> | <i></i> | x       | <i></i> |\n",
    "| determiner    | <i></i> | x       | <i></i> | <i></i> | x       | <i></i>  | <i></i> | x       | <i></i> | <i></i> |\n",
    "| preposition   | <i></i> | <i></i> | <i></i> | <i></i> | <i></i> | <i></i>  | x       | <i></i> | <i></i> | <i></i> |\n",
    "| punctuation   | <i></i> | <i></i> | <i></i> | <i></i> | <i></i> | <i></i>  | <i></i> | <i></i> | <i></i> | x       |\n",
    "\n",
    "\n",
    "Given this information, answer the following questions: \n",
    "- (A) With this simple tagset of part-of-speech tags, how many possible part-of-speech tag sequences (i.e, hidden state sequences) are there for the given sentence (observation sequence)?\n",
    "- (B) Restricting to the possibilities shown above with `x`, how many possible part-of-speech tag sequences are there?\n",
    "- (C) Given an HMM with states as part-of-speech tags and observations as words, one way to decode the observation sequence is using the brute force method below. What is the time complexity of this method in terms of the number of states ($n$) and the length of the output sequence ($T$)? You may ignore constants.    \n",
    "    - enumerate all possible hidden state sequences (i.e., enumerate all solutions)\n",
    "    - for each hidden state sequence, calculate the probability of the observation sequence given the hidden state sequence (i.e., score each solution)\n",
    "    - pick the hidden state sequence which gives the highest probability for the observation sequence (i.e., pick the best solution)    \n",
    "\n",
    "- (D) If you decode the sequence using the Viterbi algorithm instead, what will be the time complexity in terms of the number of states ($n$) and the length of the output sequence ($T$)? You may ignore constants.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 4.3: V's Solutions!\n",
    ":class: tip, dropdown\n",
    "\n",
    "- (A) 9.7 million! \n",
    "- (B) 128\n",
    "- (C) The time complexity of this approach is $\\mathcal{O}(N^T)$. \n",
    "- (D) $\\mathcal{O}(N^2T)$\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:575]",
   "language": "python",
   "name": "conda-env-575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
