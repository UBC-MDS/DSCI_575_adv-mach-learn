{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60901dc2-b158-4722-b254-4ddeb93be32f",
   "metadata": {},
   "source": [
    "# RNN Toy example of text generation with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe24e8-a76f-4a4e-b25f-677618a7fc48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We know basics of RNNs. \n",
    "- Now we'll look at a toy example for character-level text generation using RNNs. \n",
    "- Recall that given a sequence of characters, character-level text generation is the task of modeling probability distribution of the next character in the sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e29393-f835-4f9a-98b1-431c1311d173",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A toy \"hello\" RNN \n",
    "- Suppose we want to train a character-level RNN on sequence \"hello\". \n",
    "- The vocabulary is 4 and we want our model to learn the following: \n",
    "    - \"e\" should be likely given \"h\" \n",
    "    - \"l\" should be likely given \"he\" \n",
    "    - \"l\" should be likely given \"hel\" \n",
    "    - \"o\" should be likely given \"hell\"     \n",
    "\n",
    "![](img/RNN_char_generation_train.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/RNN_char_generation_train.png\" height=\"500\" width=\"500\">  -->\n",
    "<!-- <center>     -->\n",
    "\n",
    "[Source](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3731b2-37fe-416b-a228-72b2e8529f1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Shapes of input, hidden, and output weight matrices\n",
    "- Shape of $W_{xh}$ ($W$) is going to be: $4 \\times 3$\n",
    "- Shape of $W_{hh}$ ($U$) is going to be: $3 \\times 3$\n",
    "- Shape of $W_{hy}$ ($V$) is going to be: $3 \\times 4$\n",
    "$$\n",
    "h_t = g(h_{t-1}U + x_tW + b_1)\\\\\n",
    "\\hat{y}_t = \\text{softmax}(h_tV + b_2)\n",
    "$$ \n",
    "\n",
    "![](img/RNN_char_generation_train.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/RNN_char_generation_train.png\" height=\"600\" width=\"600\">  -->\n",
    "<!-- <center>   -->\n",
    "\n",
    "[Source](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e18a7-4ebc-4fe6-8057-5b48bb5a9cbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's build a simple RNN for this using `PyTorch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8d6568b-d2b7-4989-8435-69ed46cd17cb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x108150e50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670cec4-835b-490a-ba32-6aa7d17b7fd8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Let's define a mapping between indices and characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6be08e3-9bba-4705-9a23-47e2d87cfcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = [\"h\", \"e\", \"l\", \"o\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20f65b-c91c-4626-8822-37b21d1dba25",
   "metadata": {},
   "source": [
    "We need some representation for the input. Let's use one-hot representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406d1165-56fc-4ec0-8980-c767b549d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_lookup = [\n",
    "    [1, 0, 0, 0],  # h\n",
    "    [0, 1, 0, 0],  # e\n",
    "    [0, 0, 1, 0],  # l\n",
    "    [0, 0, 0, 1],  # o\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc38615-fcd4-433b-b4ac-d3305e14d716",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next let's create one-hot representation of `X`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ef7043-412a-4b1f-87a6-53fc7e8c598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [0, 1, 2, 2]  # indices for the input \"hell\"\n",
    "X_one_hot = [one_hot_lookup[x] for x in X]\n",
    "inputs = torch.Tensor(X_one_hot)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7df5b500-b3bb-4920-a4d7-ea8ab5779ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [1, 2, 2, 3]\n",
    "labels = torch.LongTensor(y)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf56b83-83d4-4cc1-b302-2b486406431f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Defining some variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "422b4d23-3402-41ce-b92a-e0bcd6fb15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4  # size of vocab\n",
    "EPOCHS = 10  # number of epochs\n",
    "input_size = 4  # size of vocab or one-hot size\n",
    "hidden_size = 3  # output from the RNN.\n",
    "batch_size = 1  # we are not batching in this toy example.\n",
    "sequence_length = 1  # we are processing characters one by one in this toy example\n",
    "num_layers = 1  # one-layer rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2da042b-5e93-40d7-a3dc-84650c27072d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class ToyRNN(nn.Module):\n",
    "    def __init__(self, debug=False):\n",
    "        super(ToyRNN, self).__init__()\n",
    "\n",
    "        # PyTorch core RNN module\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Fully connected layer for the output\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Debugging flag\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(self, hidden, x):\n",
    "        x = x.view(batch_size, sequence_length, input_size)  # reshape the input\n",
    "        if self.debug:\n",
    "            print(\"\\n\\n\")\n",
    "            print(\"Input shape = \", x.size())\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        if self.debug:\n",
    "            print(\"out shape = \", out.size())\n",
    "            print(\"Hidden shape = \", hidden.size())\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)  # reshape to pass before the output layer\n",
    "        if self.debug:\n",
    "            print(\"out shape after reshaing = \", out.size())\n",
    "\n",
    "        out = self.fc(out)\n",
    "        if self.debug:\n",
    "            print(\"out shape after passing through fc = \", out.size())\n",
    "\n",
    "        return hidden, out\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(num_layers, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ca53c-28f6-4808-b3f3-1a38c6766cab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9797fc5a-d556-4dfa-802b-ecc7b8378067",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToyRNN(\n",
      "  (rnn): RNN(4, 3, batch_first=True)\n",
      "  (fc): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ToyRNN()\n",
    "print(model)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# Loss increases as the predicted probability diverges from the actual label.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf7b36-c79f-4ca7-b768-1991cd81500b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fab2faf-26f3-47f9-a02b-c455f83bc91f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 6.082, preidcted: oeoe\n",
      "Epoch: 2, loss: 5.008, preidcted: olol\n",
      "Epoch: 3, loss: 4.393, preidcted: llll\n",
      "Epoch: 4, loss: 4.155, preidcted: llll\n",
      "Epoch: 5, loss: 3.991, preidcted: llll\n",
      "Epoch: 6, loss: 3.697, preidcted: llll\n",
      "Epoch: 7, loss: 3.280, preidcted: llll\n",
      "Epoch: 8, loss: 2.864, preidcted: ello\n",
      "Epoch: 9, loss: 2.459, preidcted: ello\n",
      "Epoch: 10, loss: 2.020, preidcted: ello\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    pred = \"\"\n",
    "    for inp, label in zip(inputs, labels):\n",
    "        hidden, output = model(hidden, inp)\n",
    "        val, idx = output.max(1)\n",
    "        pred += idx2char[idx.data[0]]\n",
    "        loss += criterion(output, torch.LongTensor([label]))\n",
    "    print(\"Epoch: %d, loss: %1.3f, preidcted: %s\" % (epoch + 1, loss, pred))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5880a5-57e8-4453-a556-b243c68f2b6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/RNN_char_generation_train.png)\n",
    "\n",
    "<!-- <center> -->\n",
    "<!-- <img src=\"img/RNN_char_generation_train.png\" height=\"600\" width=\"600\">  -->\n",
    "<!-- <center>     -->\n",
    "\n",
    "[Source](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d78730b-a440-403f-9ee4-9e4798b475ca",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We have our toy RNN for text generation! \n",
    "- For realistic text generation using RNNs, usually their variants such as LSTMs or GRUs are trained on large corpora such as Wikipedia.   \n",
    "- Note that training such models require significant computational resources, including powerful GPUs or TPUs, and substantial memory capacity. So don't try it on your laptop.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:575]",
   "language": "python",
   "name": "conda-env-575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
