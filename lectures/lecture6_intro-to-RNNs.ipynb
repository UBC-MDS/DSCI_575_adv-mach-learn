{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSCI 575: Advanced Machine Learning (in the context of Natural Language Processing (NLP) applications)\n",
    "\n",
    "UBC Master of Data Science program, 2019-20\n",
    "\n",
    "Instructor: Varada Kolhatkar [ʋəɾəda kɔːlɦəʈkər]\n",
    "\n",
    "\n",
    "## Lecture 6: Introduction to Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys, re\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN-generated music! \n",
    "\n",
    "- [Magenta PerformanceRNN](https://magenta.tensorflow.org/performance-rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning outcomes\n",
    "\n",
    "From this lecture you will be able to \n",
    "\n",
    "- explain the motivation to use RNNs\n",
    "- define vanilla or simple RNNs \n",
    "- explain parameter sharing in RNNs \n",
    "- explain the forward pass and backward pass in RNNs\n",
    "- specify different architectures of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation \n",
    "\n",
    "- Language is an inherently sequential phenomenon.\n",
    "- Reflected in the metaphors used to describe language \n",
    "    - *flow of conversation*, *news feeds*, and *twitter streams*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixed length input\n",
    "\n",
    "- ML algorithms we have seen in 571 and 572 work with fixed length input.  \n",
    "    - SVM\n",
    "    - Logistic Regression\n",
    "    - Multi-layer Perceptron\n",
    "\n",
    "- Example of fixed length input\n",
    "$$X = \\begin{bmatrix}1 & 0.8 & \\ldots & 0.3\\\\ 0 & 0 &  \\ldots & 0.4\\\\ 1 & 0.2 &  \\ldots & 0.8 \\end{bmatrix}$$ \n",
    "\n",
    "$$y = \\begin{bmatrix}1 \\\\ 0 \\\\ 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixed length input\n",
    "\n",
    "- When we used these models for sentiment analysis we created a **fixed size** input representation using `CountVectorizer`, where we had simultaneous access to all aspects of the input. \n",
    "\n",
    "$$X = \\begin{bmatrix}\\text{\"@united you're terrible. You don't understand safety\",}\\\\ \\text{\"@JetBlue safety first !! #lovejetblue\"}\\\\ \\text{\"@SouthwestAir truly the best in #customerservice!\"}\\\\ \\end{bmatrix} \\text{ and } y = \\begin{bmatrix}0 \\\\ 1 \\\\ 1 \\end{bmatrix} $$ \n",
    "<br><br>\n",
    "$$X_{counts} = \\begin{bmatrix}1 & 3 & \\ldots & 2\\\\ 1 & 0 & \\ldots & 0\\\\ 0 & 2 & \\ldots & 1\\end{bmatrix} \\text{ and } y = \\begin{bmatrix}1 \\\\ 0 \\\\ 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentiment analysis using feed-forward neural networks \n",
    "\n",
    "- Reminder: In feed-forward neural networks, \n",
    "    - all connections flow forward (no loops)\n",
    "    - each layer of hidden units is fully connected to the next\n",
    "- Pass fixed sized vector representation of text (`CountVectorizer` object) as input\n",
    "- We lose the temporal aspect of text in this representation. \n",
    "\n",
    "<img src=\"images/RNN_FFN_1_layer.png\" height=\"500\" width=\"500\"> \n",
    "   \n",
    "(Image credit: [learnopencv](https://www.learnopencv.com/understanding-feedforward-neural-networks/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How about using Markov models? \n",
    "\n",
    "- They have some temporal aspect! \n",
    "\n",
    "<img src=\"images/Markov_assumption.png\" height=\"550\" width=\"550\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall language modeling task \n",
    "\n",
    "- Recall the task of predicting the next word given a sequence. \n",
    "- What's the probability of an upcoming word?  \n",
    "    - $P(w_t|w_1,w_2,\\dots,w_{t-1})$\n",
    "    \n",
    "<blockquote>\n",
    "    I am studying medicine at UBC because I want to work as a ___.\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Language modeling: Why should we care?\n",
    "\n",
    "Powerful idea in NLP and helps in many tasks.\n",
    "- Machine translation \n",
    "    * P(In the age of data algorithms have the answer) > P(the age data of in algorithms answer the have)\n",
    "- Spelling correction\n",
    "    * My office is a 10  <span style=\"color:red\">minuet</span> bus ride from my home.  \n",
    "        * P(10 <span style=\"color:blue\">minute</span> bus ride from my home) > P(10 <span style=\"color:red\">minuet</span> bus ride from my home)\n",
    "- Speech recognition \n",
    "    * P(<span style=\"color:blue\">I read</span> a book) > P(<span style=\"color:red\">Eye red</span> a book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation: Language modeling task \n",
    "\n",
    "- Recall that when we used Markov models for this task, we made Markov assumption. \n",
    "    - Markov model: $P(w_t|w_1,w_2,\\dots,w_{t-1}) = P(w_t|w_{t-1})$\n",
    "    - Markov model with more context: $P(w_t|w_1,w_2,\\dots,w_{t-1}) = P(w_t|w_{t-2}, w_{t-1})$ \n",
    "- These models are 'memoryless' in the sense that they do not have memory beyond the previous 2, 3 or maximum $n$ steps and when $n$ becomes larger, there is sparsity problem.  \n",
    "- Also, they have huge RAM requirements because you have to store all ngrams. \n",
    "- Would a Markov model with $n=5$ predict the correct words in the following cases? \n",
    "<blockquote>\n",
    "    I am studying medicine at UBC because I want to work as a <b>doctor</b>.<br>\n",
    "    I am studying law at UBC because I want to work as a <b>lawyer</b>.<br>\n",
    "    I am studying history at UBC because I want to work as a <b>historian</b>.     \n",
    "</blockquote>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNNs motivation \n",
    "\n",
    "- RNNs can help us with this limited memory problem!\n",
    "- **RNNs are a kind of neural network model which use hidden units to remember things over time.**   \n",
    "- Condition the neural network on all previous words. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN intuition: Example\n",
    "\n",
    "- Put a number of feedforward networks together.\n",
    "- Suppose I have 1 word represented by a vector of size 4 and I want to predict something about that word, I use one feedforward neural network. \n",
    "- Suppose I have 2 words, I use 2 of these networks and put them together. \n",
    "\n",
    "<img src=\"images/RNN_two_feedforward.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "\n",
    "(Image credit: [learnopencv](https://www.learnopencv.com/understanding-feedforward-neural-networks/))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN intuition\n",
    "\n",
    "- Put a number of feedforward networks together. \n",
    "- Make connections between the hidden layers.\n",
    "- Process sequences by presenting one element at a time to the network.\n",
    "\n",
    "\n",
    "<img src=\"images/RNN_introduction.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "(Credit: [Stanford CS224d slides](http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN presentations\n",
    "\n",
    "- Unrolled presentation \n",
    "<center>\n",
    "<img src=\"images/RNN_introduction.png\" height=\"600\" width=\"600\"> \n",
    "</center> \n",
    "\n",
    "- Recursive presentation\n",
    "<img src=\"images/RNN_recursive_2.png\" height=\"300\" width=\"300\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RNN as a graphical model\n",
    "\n",
    "- Each state is a function of the previous state and the input.\n",
    "- A state contains information about the whole past sequence. \n",
    "    - $s_t = g_t(x_t, x_{t-1}, \\dots, x_2, x_1)$ \n",
    "\n",
    "<img src=\"images/RNN_dynamic_model.png\" height=\"800\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter sharing\n",
    "\n",
    "- Parameters\n",
    "    - Input to hidden weight matrix: $U$\n",
    "    - Hidden to output weight matrix: $V$    \n",
    "    - Hidden to hidden weight matrix: $W$\n",
    "    \n",
    "- **We share all weights between time steps**    \n",
    "\n",
    "<img src=\"images/RNN_dynamic_model.png\" height=\"800\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### RNN parameters\n",
    "\n",
    "- Input size: Suppose $x \\in \\mathbb{R}^d$\n",
    "- Output size: Suppose $y \\in \\mathbb{R}^q$\n",
    "- Hidden size: Suppose $s \\in \\mathbb{R}^p$\n",
    "- Three kinds of weights: $U_{d\\times p}$, $V_{p\\times q}$, $W_{p\\times p}$    \n",
    "\n",
    "<img src=\"images/RNN_dynamic_model.png\" height=\"800\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN parameters: Language modeling example\n",
    "\n",
    "- Embedding size: 300, vocabulary size: 10,000\n",
    "- Hidden layer size: 100 (memory of the network)\n",
    "- $x_t \\in \\mathbb{R}^{300}$\n",
    "- $y_t \\in \\mathbb{R}^{10000}$\n",
    "- $s_t \\in \\mathbb{R}^{100}$\n",
    "- $U_{300\\times 100}$, $V_{100\\times 10000}$, $W_{100\\times 100}$\n",
    "\n",
    "<img src=\"images/RNN_dynamic_model.png\" height=\"800\" width=\"800\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Forward pass in RNNs\n",
    "- Computing new states and output in RNNs\n",
    "\n",
    "$$\n",
    "s_t = tanh(Ws_{t-1} + Ux_t + b_1)\\\\\n",
    "\\hat{y}_t = \\text{softmax}(Vs_t + b_2)\n",
    "$$ \n",
    "\n",
    "<img src=\"images/RNN_dynamic_model.png\" height=\"800\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward pass in RNNs\n",
    "\n",
    "The matrices $U$, $V$ and $W$ are shared across time and new values for $s_t$ and $\\hat{y_t}$ are calculated at each time step.\n",
    "\n",
    "- Given: $x$, network\n",
    "- $s_0 = 0$\n",
    "- for $t$ in 1 to length($x$)\n",
    "    - $s_t = tanh(Ws_{t-1} + Ux_t + b_1$)\n",
    "    - $\\hat{y}_t = \\text{softmax}(Vs_t + b_2)$\n",
    "\n",
    "<img src=\"images/RNN_dynamic_model.png\" height=\"500\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss in RNNs\n",
    "\n",
    "- The overall loss is the summation of losses at each time step. \n",
    "\n",
    "<br>\n",
    "<img src=\"images/RNN_loss.png\" height=\"1500\" width=\"1500\"> \n",
    "\n",
    "[Credit](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backward pass in RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropogation Through Time (BPTT)\n",
    "\n",
    "- In RNNs we use a generalized version of Backpropogation called Backpropogation Through Time (BPTT)\n",
    "    - Calculating gradient at each output depends upon the current time step as well as the previous time steps. \n",
    "    \n",
    "<img src=\"files/images/RNN_backprop_TT.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "(Credit: [Stanford CS224d slides](http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Truncated backpropagation through time\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"images/RNN_truncated_backprop_TT1.png\" height=\"1000\" width=\"1000\"> \n",
    "\n",
    "[Credit](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Truncated backpropagation through time\n",
    "\n",
    "<br>\n",
    "<img src=\"images/RNN_truncated_backprop_TT2.png\" height=\"1000\" width=\"1000\"> \n",
    "\n",
    "[Credit](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Truncated backpropagation through time\n",
    "\n",
    "<br>\n",
    "<img src=\"images/RNN_truncated_backprop_TT3.png\" height=\"1000\" width=\"1000\"> \n",
    "\n",
    "[Credit](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN code in 112 lines of Python\n",
    "\n",
    "- See [the code](https://gist.github.com/karpathy/d4dee566867f8291f086) for the above in ~112 lines of Python written by Andrej Karpathy. The code has only `numpy` dependency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What can we do with RNNs?\n",
    "\n",
    "- Simple or Vanilla RNN\n",
    "\n",
    "<img src=\"images/RNN_introduction.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "- But a number of architectures are possible, which makes them a very rich family of models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN architectures\n",
    "\n",
    "- A number of possible RNN architectures\n",
    "\n",
    "<img src=\"images/RNN_architectures.png\" height=\"1000\" width=\"1000\"> \n",
    "\n",
    "[source](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### One to one \n",
    "\n",
    "- The usual feedforward neural network \n",
    "   \n",
    "<img src=\"images/RNN_architectures.png\" height=\"800\" width=\"800\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples: One to many\n",
    "\n",
    "- Music generation\n",
    "- Text generation\n",
    "- Image captioning \n",
    "\n",
    "<img src=\"images/RNN_generation.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "[Credit](https://web.stanford.edu/~jurafsky/slp3/9.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples: One to many \n",
    "\n",
    "<img src=\"images/image_captioning.png\" width=\"1000\" height=\"1000\">\n",
    "\n",
    "[Source](https://cs.stanford.edu/people/karpathy/sfmltalk.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples: Many to one\n",
    "\n",
    "- Sentiment analysis\n",
    "- Text classification \n",
    "- Video activity recognition \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many to many (sequence to sequence or encoder-decoder models)\n",
    "\n",
    "- Speech recognition \n",
    "- Machine translation \n",
    "\n",
    "<img src=\"images/RNN_many_to_many.png\" height=\"800\" width=\"800\"> \n",
    "\n",
    "- Note that the input sequence and output sequence do not have to be of same length. \n",
    "\n",
    "[source](http://cs224d.stanford.edu/lectures/CS224d-Lecture9.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- RNNs are deep-learning models to process sequential data.\n",
    "- The intuition is to put multiple feed-forward networks together and making connections between hidden layers.  \n",
    "- Unlike Markov models they are conditioned on the whole input sequence. \n",
    "- The parameters are shared across different time steps.\n",
    "- A generalized version of backpropagation called backpropagation through time is used for training the network. \n",
    "- In practice truncated backpropagation through time is used where we work through chunks. \n",
    "- A number of RNNs architectures are possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Post assessment: True or False \n",
    "\n",
    "1. RNNs pass along information between time steps through hidden layers.\n",
    "2. RNNs are appropriate only for text data.\n",
    "3. Each time step in RNN has a different set of weights.\n",
    "4. Similar to Markov chains, RNNs only consider the last few observations when making predictions.\n",
    "5. RNNs are unsupervised ML models. \n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resources\n",
    "\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- [Coursera: NLP sequence models](https://www.coursera.org/lecture/nlp-sequence-models/recurrent-neural-network-model-ftkzt)\n",
    "- [RNN code in 112 lines of Python](https://gist.github.com/karpathy/d4dee566867f8291f086#file-min-char-rnn-py-L112)\n",
    "- [Sequence processing with Recurrent Neural Networks](https://web.stanford.edu/~jurafsky/slp3/9.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
