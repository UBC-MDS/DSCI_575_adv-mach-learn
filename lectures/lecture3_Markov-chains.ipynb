{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSCI 575: Advanced Machine Learning (in the context of Natural Language Processing (NLP) applications)\n",
    "\n",
    "UBC Master of Data Science program, 2019-20\n",
    "\n",
    "Instructor: Varada Kolhatkar [ʋəɾəda kɔːlɦəʈkər]\n",
    "\n",
    "## Lecture 3: Markov models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning outcomes\n",
    "\n",
    "From this lesson you will be able to\n",
    "\n",
    "- Define Markov chains.\n",
    "- Carry out generation and inference with Markov chains. \n",
    "- Compute the probability of a sequence of states. \n",
    "- Explain the general idea of a stationary distribution. \n",
    "- Justify and apply Markov chains to compute the probability of natural language sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Does this look like Python code?\n",
    "\n",
    "```\n",
    "import sys\n",
    "import warnings\n",
    "import ast\n",
    "import numpy.core.overrides import set_module\n",
    "# While not in __all__, matrix_power used to be defined here, so we import\n",
    "# it for backward compatibility\n",
    "    getT = T.fget\n",
    "    getI = I.fget\n",
    "```\n",
    "\n",
    "```\n",
    "def _from_string(data):\n",
    "    for char in '[]':\n",
    "        data = data.replace(char, '')\n",
    "    rows = str.split(';')\n",
    "    rowtup = []\n",
    "        for row in rows:\n",
    "        trow = newrow\n",
    "        coltup.append(thismat)\n",
    "        rowtup.append(concatenate(coltup, axis=-1))\n",
    "            return NotImplemented\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A high-level description of how the text was generated? \n",
    "\n",
    "- Suppose you have a corpus of thousands of Python programs. \n",
    "- Assume a discrete probability distribution over all unique words in the corpus.\n",
    "- You scroll through the corpus note down the first word you see on that page. \n",
    "- Choose successive word based on the current word and continue for a while...   \n",
    "\n",
    "<img src=\"images/Python_generation_Markov.png\" height=\"550\" width=\"550\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov chains you have seen in MDS so far \n",
    "\n",
    "- DSCI 512\n",
    "    - You wrote code to generate text using Markov models of language. \n",
    "- DSCI 553\n",
    "    - You used it as a mathematical tool to simulate from the posterior distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov chain idea and applications \n",
    "\n",
    "- Often we need to make inferences about evolving environments.\n",
    "- Represent the state of the world at each specific point via a series of snapshots or time slices. \n",
    "- Predict future depending upon \n",
    "    - what the current state is and \n",
    "    - the probability of change    \n",
    "\n",
    "- Examples: \n",
    "    - Weather: Given that today is cold, what will be the weather tomorrow? \n",
    "    - Stock prices: Given the current market conditions what will be the stock prices tomorrow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How Markov chains are relevant in NLP?\n",
    "\n",
    "- Language is a temporal phenomenon.When we speak, we produce streams of indefinite length. \n",
    "- A simplistic model of language is an n-gram language model which is based on Markov chains.\n",
    "\n",
    "<img src=\"images/Markov_autocompletion.png\" height=\"500\" width=\"500\"> \n",
    "\n",
    "\n",
    "<img src=\"images/bigram_probabilities.png\" height=\"500\" width=\"500\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov’s own application of his chains  (1913)\n",
    "\n",
    "\n",
    "- Studied the sequence of 20,000 letters in A. S. Pushkin's poem _Eugeny Onegin_.\n",
    "\n",
    " \n",
    "<img src=\"images/Markov_Pushkin.png\" height=\"800\" width=\"800\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov assumption\n",
    "\n",
    "\n",
    "<img src=\"images/Markov_assumption.png\" height=\"550\" width=\"550\"> \n",
    "\n",
    "**Markov assumption: The future is conditionally independent of the past given present**\n",
    "\n",
    "- In the example above \n",
    "\n",
    "    $$P(S_{3}|S_0, S_1, S_2) \\approx P(S_{3} | S_2)$$\n",
    "\n",
    "- Generalizing it to $t$ time steps\n",
    "\n",
    "$$P(S_{t+1}|S_0, \\dots, S_t) \\approx P(S_{t+1} | S_t)$$\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's look at the details of Markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete Markov chain example \n",
    "\n",
    "\n",
    "<img src=\"images/Markov_weather_example.png\" height=\"1000\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete Markov chain ingredients: State space\n",
    "\n",
    "<img src=\"images/Markov_chain.png\" height=\"300\" width=\"300\"> \n",
    "\n",
    "- We have discrete timesteps: $t = 0, t = 1, \\dots$.\n",
    "- **State space**: We have a finite set of possible states we can be in at time $t$\n",
    "    - Represent the unique observations in the world. \n",
    "    - We can be in only one state at a given time. \n",
    "    - Here $S = \\{HOT, COLD, WARM\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete Markov chain ingredients: Initial probability distribution over states\n",
    "<img src=\"images/Markov_chain.png\" height=\"300\" width=\"300\"> \n",
    "\n",
    "- State space: $S = \\{\\text{HOT, COLD, WARM}\\}$, \n",
    "- We could start in any state. The probability of starting with a particular state is given by an **initial discrete probability distribution over states**.        \n",
    "    - Here, $\\pi_0 = \\begin{bmatrix} P(\\text{HOT at time 0}) & P(\\text{COLD at time 0}) & P(\\text{WARM at time 0}) \\end{bmatrix} = \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}$    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete Markov chain ingredients: Transition probability matrix\n",
    "\n",
    "<img src=\"images/Markov_chain.png\" height=\"300\" width=\"300\"> \n",
    "\n",
    "\n",
    "- State space: $S = \\{\\text{HOT, COLD, WARM}\\}$, initial probability distribution: $\\pi_0 = \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}$\n",
    "- **Transition probability matrix** $T$, where each $a_{ij}$ represents the probability of moving from state $s_i$ to state $s_j$, such that $\\sum_{j=1}^{n} a_{ij} = 1, \\forall i$ \n",
    "\n",
    "$$ T = \n",
    "\\begin{bmatrix}\n",
    "\\text{P(HOT|HOT)} & \\text{P(COLD|HOT)} & \\text{P(WARM|HOT)}\\\\\n",
    "\\text{P(HOT|COLD)} & \\text{P(COLD|COLD)} & \\text{P(WARM|COLD)}\\\\\n",
    "\\text{P(HOT|WARM)} & \\text{P(COLD|WARM)} & \\text{P(WARM|WARM)}\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\\\\\n",
    "0.2 & 0.5 & 0.3\\\\\n",
    "0.3 & 0.1 & 0.6\\\\    \n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "- Note that each row sums to 1.0. \n",
    "- Each state has a probability of staying in the same state (or transitioning to itself).\n",
    "- _Note that some people use the the notation where the columns sum to one._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Weather example: state space, initial probability distribution, transition probability matrix\n",
    "\n",
    "$S = \\{\\text{HOT, COLD, WARM}\\}$, $\\pi_0 = \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}$, T = \n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\\\\\n",
    "0.2 & 0.5 & 0.3\\\\\n",
    "0.3 & 0.1 & 0.6\\\\    \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/Markov_chain.png\" height=\"550\" width=\"550\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov chain general definition \n",
    "\n",
    "- A set of $n$ states: $S = \\{s_1, s_2, ..., s_n\\}$\n",
    "- A set of discrete initial probability distribution over states $\\pi_0 = \\begin{bmatrix} \\pi_{s_1} & \\pi_{s_2} & \\dots & \\pi_{s_n} \\end{bmatrix}$\n",
    "\n",
    "- Transition probability matrix $T$, where each $a_{ij}$ represents the probability of moving from state $s_i$ to state $s_j$, such that $\\sum_{j=1}^{n} a_{ij} = 1, \\forall i$ \n",
    "\n",
    "\n",
    "$$ T = \n",
    "\\begin{bmatrix}\n",
    "    a_{11}       & a_{12} & a_{13} & \\dots & a_{1n} \\\\\n",
    "    a_{21}       & a_{22} & a_{23} & \\dots & a_{2n} \\\\\n",
    "    \\dots \\\\\n",
    "    a_{n1}       & a_{n2} & a_{n3} & \\dots & a_{nn}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Homogeneous Markov chains\n",
    "\n",
    "- Transition probabilities are the same for all $t$.\n",
    "- In this class we will assume homogeneous Markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### What can we do with Markov chains? \n",
    "\n",
    "- **Predict probabilities of sequences of states**\n",
    "- **Inference**: compute probability of being in a particular state at time $t$.    \n",
    "- **Stationary distribution**: Find the steady state after running for a long time\n",
    "- Generation: generate sequences that follow the probabilities of the states. \n",
    "    - You will be doing this in the lab. \n",
    "- Decoding: compute most likely sequences of states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predict probabilities of sequences of states \n",
    "\n",
    "- Given the Markov model: $S = \\{\\text{HOT, COLD, WARM}\\}$, \n",
    "$\\pi_0 = \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}$, T = \n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\\\\\n",
    "0.2 & 0.5 & 0.3\\\\\n",
    "0.3 & 0.1 & 0.6\\\\    \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "- Compute the probability of the sequences: HOT, HOT, WARM, COLD\n",
    "    - Markov assumption: $P(S_{t+1}|S_{0}, S_1, \\dots, S_t) \\approx P(S_{t+1}| S_t)$\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\textrm{HOT, HOT, WARM, COLD}) =& P(\\textrm{HOT}) \\times P(\\textrm{HOT|HOT})\\\\ \n",
    "                                  & \\times P(\\textrm{WARM|HOT})\\\\\n",
    "                                  & \\times P(\\textrm{COLD|WARM})\\\\\n",
    "                                 =& 0.5  \\times 0.5 \\times 0.3 \\times 0.1\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "<img src=\"images/Markov_chain.png\" height=\"300\" width=\"300\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Your turn (Activity: 5 minutes)\n",
    "\n",
    "- Pause the video and predict probabilities of the following sequences of states on your own. \n",
    "    1. COLD, COLD, WARM\n",
    "    2. HOT, COLD, HOT, COLD\n",
    "    \n",
    "Hint: If we want to predict the future, all that matters is the current state.\n",
    "\n",
    "$S = \\{\\text{HOT, COLD, WARM}\\}$, \n",
    "$\\pi_0 = \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}$, T = \n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\\\\\n",
    "0.2 & 0.5 & 0.3\\\\\n",
    "0.3 & 0.1 & 0.6\\\\    \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "<img src=\"images/Markov_chain.png\" height=\"500\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference \n",
    "\n",
    "- **Compute probability of being in a particular state at time $t$.**\n",
    "- Example: What is the probability of HOT at time 1?\n",
    "    * P(HOT at time zero) $\\times$ P(HOT|HOT) + P(COLD at time zero) $\\times$ P(HOT|COLD) + P(WARM at time zero) $\\times$ P(HOT|WARM) = $0.5 \\times 0.5 + 0.3 \\times 0.2 + 0.2\\times 0.3 = 0.37$\n",
    "    \n",
    "<img src=\"images/Markov_chain.png\" height=\"400\" width=\"400\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference: What is the probability of HOT at time 1?\n",
    "- P(HOT at time zero) $\\times$ P(HOT|HOT) + P(COLD at time zero) $\\times$ P(HOT|COLD) + P(WARM at time zero) $\\times$ P(HOT|WARM) = $0.5 \\times 0.5 + 0.3 \\times 0.2 + 0.2\\times 0.3 = 0.37$    \n",
    "- Dot product between $\\pi_0$ and the first column of the transition matrix!\n",
    "\n",
    "$$\\pi_0 = \\begin{bmatrix} P(\\text{HOT at time 0}) & P(\\text{COLD at time 0}) & P(\\text{WARM at time 0}) \\end{bmatrix} = \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}$$\n",
    "\n",
    "$$ T = \n",
    "\\begin{bmatrix}\n",
    "\\text{P(HOT|HOT)} & \\text{P(COLD|HOT)} & \\text{P(WARM|HOT)}\\\\\n",
    "\\text{P(HOT|COLD)} & \\text{P(COLD|COLD)} & \\text{P(WARM|COLD)}\\\\\n",
    "\\text{P(HOT|WARM)} & \\text{P(COLD|WARM)} & \\text{P(WARM|WARM)}\\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\\\\\n",
    "0.2 & 0.5 & 0.3\\\\\n",
    "0.3 & 0.1 & 0.6\\\\    \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "<img src=\"files/images/Markov_chain.png\" height=\"400\" width=\"400\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference: What is the probability of HOT, COLD, WARM at time 1?\n",
    "\n",
    "$$\\pi_1 = \\pi_0T$$\n",
    "\n",
    "$$\\pi_0 = \\begin{bmatrix} P(\\text{HOT at time 0}) & P(\\text{COLD at time 0}) & P(\\text{WARM at time 0}) \\end{bmatrix} = \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}$$\n",
    "\n",
    "$$ T = \n",
    "\\begin{bmatrix}\n",
    "\\text{P(HOT|HOT)} & \\text{P(COLD|HOT)} & \\text{P(WARM|HOT)}\\\\\n",
    "\\text{P(HOT|COLD)} & \\text{P(COLD|COLD)} & \\text{P(WARM|COLD)}\\\\\n",
    "\\text{P(HOT|WARM)} & \\text{P(COLD|WARM)} & \\text{P(WARM|WARM)}\\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\\\\\n",
    "0.2 & 0.5 & 0.3\\\\\n",
    "0.3 & 0.1 & 0.6\\\\    \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "$$\\pi_1 = \\begin{bmatrix} P(\\text{HOT at time 1}) & P(\\text{COLD at time 1}) & P(\\text{WARM at time 1}) \\end{bmatrix} =  \\begin{bmatrix} 0.5 & 0.3 & 0.2 \\end{bmatrix}\\begin{bmatrix} 0.5 & 0.2 & 0.3\\\\ 0.2 & 0.5 & 0.3\\\\ 0.3 & 0.1 & 0.6\\\\ \\end{bmatrix} = \\begin{bmatrix}0.37 & 0.27 & 0.36\\end{bmatrix}$$\n",
    "\n",
    "<img src=\"files/images/Markov_chain.png\" height=\"300\" width=\"300\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference: What is the probability of HOT, COLD, WARM at time 2?\n",
    "- Multiply $\\pi_0$ by the transition matrix\n",
    "    $$\\pi_2 = \\pi_1T$$\n",
    "\n",
    "$$\\pi_1 = \\begin{bmatrix} P(\\text{HOT at time 1}) & P(\\text{COLD at time 1}) & P(\\text{WARM at time 1}) \\end{bmatrix} =  \\begin{bmatrix}0.37 & 0.27 & 0.36\\end{bmatrix}$$\n",
    "\n",
    "$$ T = \n",
    "\\begin{bmatrix}\n",
    "\\text{P(HOT|HOT)} & \\text{P(COLD|HOT)} & \\text{P(WARM|HOT)}\\\\\n",
    "\\text{P(HOT|COLD)} & \\text{P(COLD|COLD)} & \\text{P(WARM|COLD)}\\\\\n",
    "\\text{P(HOT|WARM)} & \\text{P(COLD|WARM)} & \\text{P(WARM|WARM)}\\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\\\\\n",
    "0.2 & 0.5 & 0.3\\\\\n",
    "0.3 & 0.1 & 0.6\\\\    \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "$$\\pi_2 = \\begin{bmatrix} P(\\text{HOT at time 2}) & P(\\text{COLD at time 2}) & P(\\text{WARM at time 2} \\end{bmatrix} = \\pi_1T = \\begin{bmatrix}0.347 & 0.245 & 0.408\\end{bmatrix}$$\n",
    "\n",
    "<img src=\"files/images/Markov_chain.png\" height=\"300\" width=\"300\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference: probability of being in a particular state at time $t$\n",
    "\n",
    "- Calculate \n",
    "\n",
    "$$\\pi_t = \\pi_{t-1} \\times \\text{transition probability matrix } T$$  \n",
    "\n",
    "- Applying the matrix multiplication to the current state probabilities does an update to the state probabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi_0:  [[0.5 0.3 0.2]]\n",
      "pi_1:  [[0.37 0.27 0.36]]\n",
      "pi_2:  [[0.347 0.245 0.408]]\n",
      "pi_3:  [[0.3449 0.2327 0.4224]]\n",
      "pi_4:  [[0.34571 0.22757 0.42672]]\n"
     ]
    }
   ],
   "source": [
    "pi0 = np.matrix('0.5, 0.3, 0.2]')\n",
    "T = np.matrix('0.5 0.2 0.3; 0.2 0.5 0.3; 0.3 0.1 0.6')\n",
    "print(\"pi_0: \", pi0)\n",
    "print(\"pi_1: \", pi0@T)\n",
    "print(\"pi_2: \", pi0@T@T)\n",
    "print(\"pi_3: \", pi0@T@T@T)\n",
    "print(\"pi_4: \", pi0@T@T@T@T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.34571, 0.22757, 0.42672]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi0*np.linalg.matrix_power(T,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial probability distribution over states:  [[0.5 0.3 0.2]]\n",
      "The transition probability matrix: \n",
      " [[0.5 0.2 0.3]\n",
      " [0.2 0.5 0.3]\n",
      " [0.3 0.1 0.6]]\n",
      "State probabilities at time step  0 [[0.5 0.3 0.2]]\n",
      "State probabilities at time step  1 [[0.37 0.27 0.36]]\n",
      "State probabilities at time step  2 [[0.347 0.245 0.408]]\n",
      "State probabilities at time step  3 [[0.3449 0.2327 0.4224]]\n",
      "State probabilities at time step  4 [[0.34571 0.22757 0.42672]]\n",
      "State probabilities at time step  5 [[0.346385 0.225599 0.428016]]\n",
      "State probabilities at time step  6 [[0.3467171 0.2248781 0.4284048]]\n",
      "State probabilities at time step  7 [[0.34685561 0.22462295 0.42852144]]\n",
      "State probabilities at time step  8 [[0.34690883 0.22453474 0.42855643]]\n",
      "State probabilities at time step  9 [[0.34692829 0.22450478 0.42856693]]\n",
      "State probabilities at time step  10 [[0.34693518 0.22449474 0.42857008]]\n",
      "State probabilities at time step  11 [[0.34693756 0.22449141 0.42857102]]\n",
      "State probabilities at time step  12 [[0.34693837 0.22449032 0.42857131]]\n",
      "State probabilities at time step  13 [[0.34693864 0.22448997 0.42857139]]\n",
      "State probabilities at time step  14 [[0.34693873 0.22448985 0.42857142]]\n"
     ]
    }
   ],
   "source": [
    "def print_pi_over_time(pi0, T, steps=10):\n",
    "    current = pi0\n",
    "    for i in range(steps):    \n",
    "        print('State probabilities at time step ', i, current)\n",
    "        current = current@T\n",
    "        \n",
    "pi0 = np.matrix('0.5, 0.3, 0.2]')\n",
    "print(\"Initial probability distribution over states: \", pi0)\n",
    "T = np.matrix('0.5 0.2 0.3; 0.2 0.5 0.3; 0.3 0.1 0.6')\n",
    "print(\"The transition probability matrix: \\n\", T)\n",
    "print_pi_over_time(pi0, T, steps=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stationary distribution\n",
    "\n",
    "- A stationary distribution of a Markov chain is a probability distribution over states that remains unchanged in the Markov chain as time progresses.\n",
    "\n",
    "- A probability distribution $\\pi$ on states $S$ is stationary where the following holds for the transition matrix $T$.    \n",
    "\n",
    "\n",
    "$$\\pi T=\\pi$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stationary distribution: SkyTrain example scenario\n",
    "\n",
    "<blockquote>\n",
    "Suppose TransLink launches Downtown to UBC SkyTrain. In the first month of operation it was found that 20% of the commuters going to UBC started using it and 80% of the commuters were still using other modes of transportation. The following transition matrix was determined from the records of other transit systems. \n",
    "</blockquote>\n",
    "\n",
    "\n",
    "$$S = \\{\\text{SkyTrain, Other}\\}, \\pi_0 = \\begin{bmatrix} 0.20 & 0.80 \\end{bmatrix}, \n",
    "T = \\begin{bmatrix}\n",
    "0.9 & 0.1\\\\\n",
    "0.4 & 0.6\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Labeled\\_T = \n",
    "\\begin{bmatrix}\n",
    "     & \\text{SkyTrain} & \\text{Other}\\\\\n",
    "\\text{SkyTrain}  & 0.9 & 0.1\\\\\n",
    "\\text{Other} & 0.4 & 0.6\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We might want to answer the following questions\n",
    "\n",
    "1. What percentage of the commuters will be using the SkyTrain after two months? \n",
    "2. What about after three months?\n",
    "2. What's the percentage of the commuters using the SkyTrain after the service has been in place for a long time? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What percentage of the commuters will be using the SkyTrain after two months and after three months?\n",
    "\n",
    "- State probability distribution after **one** month (initial state probability distribution)\n",
    "    - $\\pi_0 = \\begin{bmatrix} 0.20 & 0.80 \\end{bmatrix}$\n",
    "- State probability distribution after **two** months:\n",
    "    - $\\pi_1 = \\pi_0 T = \\begin{bmatrix} 0.20 & 0.80 \\end{bmatrix} \\begin{bmatrix} 0.9 & 0.1\\\\ 0.4 & 0.6\\\\ \\end{bmatrix} = \\begin{bmatrix} 0.5 & 0.5 \\end{bmatrix}$  \n",
    "- State probability distribution after **three** months:\n",
    "    - $\\pi_2 = \\pi_1 T =  \\begin{bmatrix} 0.5 & 0.5 \\end{bmatrix} \\begin{bmatrix} 0.9 & 0.1\\\\ 0.4 & 0.6\\\\ \\end{bmatrix} = \\begin{bmatrix} 0.65 & 0.35 \\end{bmatrix}$\n",
    "\n",
    "- Big improvement at each time step!! How long does this continue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State probabilities at time step  0 [[0.2 0.8]]\n",
      "State probabilities at time step  1 [[0.5 0.5]]\n",
      "State probabilities at time step  2 [[0.65 0.35]]\n",
      "State probabilities at time step  3 [[0.725 0.275]]\n",
      "State probabilities at time step  4 [[0.7625 0.2375]]\n",
      "State probabilities at time step  5 [[0.78125 0.21875]]\n",
      "State probabilities at time step  6 [[0.790625 0.209375]]\n",
      "State probabilities at time step  7 [[0.7953125 0.2046875]]\n",
      "State probabilities at time step  8 [[0.79765625 0.20234375]]\n",
      "State probabilities at time step  9 [[0.79882813 0.20117188]]\n",
      "State probabilities at time step  10 [[0.79941406 0.20058594]]\n",
      "State probabilities at time step  11 [[0.79970703 0.20029297]]\n",
      "State probabilities at time step  12 [[0.79985352 0.20014648]]\n",
      "State probabilities at time step  13 [[0.79992676 0.20007324]]\n",
      "State probabilities at time step  14 [[0.79996338 0.20003662]]\n",
      "State probabilities at time step  15 [[0.79998169 0.20001831]]\n",
      "State probabilities at time step  16 [[0.79999084 0.20000916]]\n",
      "State probabilities at time step  17 [[0.79999542 0.20000458]]\n",
      "State probabilities at time step  18 [[0.79999771 0.20000229]]\n",
      "State probabilities at time step  19 [[0.79999886 0.20000114]]\n",
      "State probabilities at time step  20 [[0.79999943 0.20000057]]\n",
      "State probabilities at time step  21 [[0.79999971 0.20000029]]\n",
      "State probabilities at time step  22 [[0.79999986 0.20000014]]\n",
      "State probabilities at time step  23 [[0.79999993 0.20000007]]\n",
      "State probabilities at time step  24 [[0.79999996 0.20000004]]\n",
      "State probabilities at time step  25 [[0.79999998 0.20000002]]\n",
      "State probabilities at time step  26 [[0.79999999 0.20000001]]\n",
      "State probabilities at time step  27 [[0.8 0.2]]\n",
      "State probabilities at time step  28 [[0.8 0.2]]\n",
      "State probabilities at time step  29 [[0.8 0.2]]\n",
      "State probabilities at time step  30 [[0.8 0.2]]\n",
      "State probabilities at time step  31 [[0.8 0.2]]\n",
      "State probabilities at time step  32 [[0.8 0.2]]\n",
      "State probabilities at time step  33 [[0.8 0.2]]\n",
      "State probabilities at time step  34 [[0.8 0.2]]\n",
      "State probabilities at time step  35 [[0.8 0.2]]\n",
      "State probabilities at time step  36 [[0.8 0.2]]\n",
      "State probabilities at time step  37 [[0.8 0.2]]\n",
      "State probabilities at time step  38 [[0.8 0.2]]\n",
      "State probabilities at time step  39 [[0.8 0.2]]\n"
     ]
    }
   ],
   "source": [
    "pi_0 = np.matrix('0.2 0.8')\n",
    "T = np.matrix('0.9 0.1; 0.4 0.6')\n",
    "print_pi_over_time(pi_0, T, steps = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stationary distribution\n",
    "\n",
    "- Seems like after the $27^{th}$ time step, there is not any change in the state probabilities.\n",
    "- Seems like we have reached a steady state at $\\pi = \\begin{bmatrix} 0.80 & 0.20 \\end{bmatrix}$ such that\n",
    "\n",
    "$$\\begin{bmatrix} 0.80 & 0.20 \\end{bmatrix} \\begin{bmatrix} 0.9 & 0.1\\\\ 0.4 & 0.6\\\\ \\end{bmatrix} = \\begin{bmatrix} 0.80 & 0.20 \\end{bmatrix} $$\n",
    "\n",
    "- So the distribution $\\pi = \\begin{bmatrix} 0.80 & 0.20 \\end{bmatrix}$ is a stationary distribution in this case because we have $\\pi T = \\pi$. \n",
    "- What's the percentage of the commuters using the SkyTrain after the service has been in place for a long time? \n",
    "    - In the long run we can expect 80% of the commuters using the SkyTrain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditions for stationary distribution\n",
    "\n",
    "- Does a stationary distribution $\\pi$ exist and is it unique?\n",
    "- Under mild assumptions, a Markov chain has a stationary distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditions for stationary distribution\n",
    "\n",
    "- Sufficient condition for existence/uniqueness is positive transitions\n",
    "    * $P(s_t | s_{t-1}) > 0$\n",
    "    \n",
    "- Weaker sufficient conditions for existence/uniqueness\n",
    "    * _Irreducible_ \n",
    "        - A Markov chain is irreducible if it is possible to get to any state from any state.\n",
    "        - It does not get stuck in part of the graph.     \n",
    "    * _Aperiodic_        \n",
    "        - Loosely, a Markov chain is aperiodic if it does not keep repeating the same sequence. \n",
    "        - A bit complicated definition. Check [this](https://en.wikipedia.org/wiki/Markov_chain#Periodicity) if you  want to know the formal definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Irreducibility and aperiodicity\n",
    "\n",
    "- Which chains are irreducible? Which ones are aperiodic?\n",
    "    * _Irreducible_ (doesn’t get stuck in part of the graph)\n",
    "    * _Aperiodic_ (doesn’t keep repeating same sequence).    \n",
    "<img src=\"images/Markov_irreducibility_aperiodicity.png\" height=\"900\" width=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to estimate the stationary distribution?\n",
    "\n",
    "- Power iteration method\n",
    "    - Multiply $\\pi_0$ by powers of the transition matrix $T$ until the product looks stable. \n",
    "- Taking the eigenvalue decomposition of the transition matrix.\n",
    "$$\\pi T=\\pi$$\n",
    "- Through Monte Carlo simulation.\n",
    "- In some cases (not always) simply counting the occurrences (lab). \n",
    "\n",
    "There are other ways too! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning Markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning Markov chains\n",
    "\n",
    "- Learning Markov chains is just counting.\n",
    "    * Similar to naive Bayes\n",
    "    \n",
    "- Given $n$ samples, MLE for homogeneous Markov chain is:\n",
    "\n",
    "    * Initial: $P(s_i) = \\frac{\\text{number of times we start in } s_i}{n} $\n",
    "\n",
    "    * Transition: $P(s_j|s_{i}) = \\frac{\\text{number of times we moved from } s_{i} \\text{ to } s_j}{\\text{number of times we moved from } s_{i} \\text{ to } anything}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Language example\n",
    "\n",
    "- Suppose you want to learn a Markov chain for words in a corpus of $n$ documents.\n",
    "- Set of states is the set of all unique words in the corpus.\n",
    "- Calculate the initial probability distribution $\\pi_0$\n",
    "    - For all states (unique words) $w_i$, compute $\\frac{\\text{number of times a document starts in } w_i}{n} $ \n",
    "    \n",
    "- Calculate the transition probabilities for all state combinations $w_i$ and $w_j$\n",
    "    - $\\frac{\\text{number of times } w_i \\text{ is followed by } w_j}{\\text{number of times } w_i \\text{ is followed by anything}}$ \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>’</th>\n",
       "      <th>s</th>\n",
       "      <th>in</th>\n",
       "      <th>a</th>\n",
       "      <th>name</th>\n",
       "      <th>rose</th>\n",
       "      <th>?</th>\n",
       "      <th>would</th>\n",
       "      <th>by</th>\n",
       "      <th>any</th>\n",
       "      <th>other</th>\n",
       "      <th>smell</th>\n",
       "      <th>as</th>\n",
       "      <th>sweet</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rose</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smell</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ’    s   in    a  name  rose    ?  would   by  any  other  smell  \\\n",
       "what   1.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "’      0.0  1.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "s      0.0  0.0  1.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "in     0.0  0.0  0.0  1.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "a      0.0  0.0  0.0  0.0   1.0   1.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "name   0.0  0.0  0.0  0.0   0.0   0.0  1.0    1.0  0.0  0.0    0.0    0.0   \n",
       "?      0.0  0.0  0.0  1.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "rose   0.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  1.0  0.0    0.0    0.0   \n",
       "by     0.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  1.0    0.0    0.0   \n",
       "any    0.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    1.0    0.0   \n",
       "other  0.0  0.0  0.0  0.0   1.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "would  0.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    1.0   \n",
       "smell  0.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "as     0.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "sweet  0.0  0.0  0.0  0.0   0.0   0.0  0.0    0.0  0.0  0.0    0.0    0.0   \n",
       "\n",
       "        as  sweet    .  \n",
       "what   0.0    0.0  0.0  \n",
       "’      0.0    0.0  0.0  \n",
       "s      0.0    0.0  0.0  \n",
       "in     0.0    0.0  0.0  \n",
       "a      0.0    0.0  0.0  \n",
       "name   0.0    0.0  0.0  \n",
       "?      0.0    0.0  0.0  \n",
       "rose   0.0    0.0  0.0  \n",
       "by     0.0    0.0  0.0  \n",
       "any    0.0    0.0  0.0  \n",
       "other  0.0    0.0  0.0  \n",
       "would  0.0    0.0  0.0  \n",
       "smell  1.0    0.0  0.0  \n",
       "as     0.0    1.0  0.0  \n",
       "sweet  0.0    0.0  1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kant_tokens = tuple(nltk.word_tokenize(kant_text))\n",
    "toy_corpus = \"What’s in a name? A rose by any other name would smell as sweet. \"\n",
    "toy_corpus_tokens = nltk.word_tokenize(toy_corpus.lower())\n",
    "\n",
    "frequencies = defaultdict(Counter)\n",
    "for i in range(len(toy_corpus_tokens) - 1):\n",
    "    frequencies[toy_corpus_tokens[i: i + 1][0]][toy_corpus_tokens[i + 1]] += 1\n",
    "    \n",
    "freq_df = pd.DataFrame(frequencies).transpose()\n",
    "freq_df = freq_df.fillna(0)\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applications of Markov chains in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Application1: Markov’s own application of his chains\n",
    "- Studied the sequence of 20,000 letters in A. S. Pushkin's poem _Eugeny Onegin_.\n",
    "- Gave the stationary distribution for vowels and consonants\n",
    "    * $\\pi = [0.432, 0.568]$, $S = \\{\\text{vowel, consonant}\\}, T =\n",
    "    \\begin{bmatrix}\n",
    "         & \\text{vowel} & \\text{consonant}\\\\\n",
    "    \\text{vowel}  & 0.128 & 0.872\\\\\n",
    "    \\text{consonant} & 0.663 & 0.337\\\\\n",
    "    \\end{bmatrix}\n",
    "    $\n",
    "\n",
    "- Stationary distribution in this case can be calculated as: \n",
    "$$\\begin{bmatrix}\n",
    "    \\frac{\\text{# vowels}}{\\text{total number of characters}} & \\frac{\\text{# consonants}}{\\text{total number of characters}}\\\\\n",
    "    \\end{bmatrix} $$\n",
    "\n",
    "<img src=\"images/Markov_Pushkin.png\" height=\"500\" width=\"500\"> s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43188 0.56812]]\n",
      "[[0.4319442 0.5680558]]\n",
      "[[0.4319442 0.5680558]]\n",
      "[[0.43190985 0.56809015]]\n"
     ]
    }
   ],
   "source": [
    "# Markov's Pushkin Onegin consonant vowel probabilities\n",
    "pi = np.matrix('0.432 0.568')\n",
    "T = np.matrix('0.128 0.872; 0.663 0.337')\n",
    "print(pi@T)\n",
    "print(pi@T@T)\n",
    "print(pi@T@T)\n",
    "print(pi@T@T@T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov’s own application of his chains\n",
    "\n",
    "- Markov also studied the sequence of 100,000 letters in S. T. Aksakov's novel \"The Childhood of Bagrov, the Grandson\" (tedious calculation)\n",
    "- Gave the stationary distribution for vowels and consonants.\n",
    "    * $\\pi = [0.449,0.551]$ \n",
    "    * $S = \\{\\text{vowel, consonant}\\}$ \n",
    "    * \n",
    "    $ T = \n",
    "    \\begin{bmatrix}\n",
    "         & \\text{vowel} & \\text{consonant}\\\\\n",
    "    \\text{vowel}  & 0.552 & 0.448\\\\\n",
    "    \\text{consonant} & 0.365 & 0.635\\\\\n",
    "    \\end{bmatrix}\n",
    "    $\n",
    "    \n",
    "- Stationary distribution in this case can be calculated as: \n",
    "$$\\begin{bmatrix}\n",
    "    \\frac{\\text{# vowels}}{\\text{total number of characters}} & \\frac{\\text{# consonants}}{\\text{total number of characters}}\\\\\n",
    "    \\end{bmatrix} $$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 [[0.449 0.551]]\n",
      "Step  1 [[0.448963 0.551037]]\n",
      "Step  2 [[0.44895608 0.55104392]]\n",
      "Step  3 [[0.44895479 0.55104521]]\n",
      "Step  4 [[0.44895455 0.55104545]]\n",
      "Step  5 [[0.4489545 0.5510455]]\n",
      "Step  6 [[0.44895449 0.55104551]]\n",
      "Step  7 [[0.44895449 0.55104551]]\n",
      "Step  8 [[0.44895449 0.55104551]]\n",
      "Step  9 [[0.44895449 0.55104551]]\n",
      "Step  10 [[0.44895449 0.55104551]]\n"
     ]
    }
   ],
   "source": [
    "# Markov's stationary distribution for S. T. Aksakov's novel \"The Childhood of Bagrov, the Grandson\"\n",
    "pi = np.matrix('0.449,0.551')\n",
    "T = np.matrix('0.552 0.448; 0.365 0.635')\n",
    "print_pi_over_time(pi, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Application2: Ngram language models\n",
    "\n",
    "- Suppose your states are words and you are computing probabilities of sequences of words.  \n",
    "- What does it tell us? \n",
    "    - Which sequence of words is more likely to occur in English?\n",
    "\n",
    "<blockquote>\n",
    "P(In the age of data algorithms have the answer) $>$ <br>\n",
    "p(The age data of in algorithms answer the have) \n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Language models\n",
    "\n",
    "- Compute the probability of a sentence or a sequence of words\n",
    "$P(w_1, w_2,\\dots,w_t)$\n",
    "\n",
    "- A related task: What's the probability of an upcoming word? \n",
    "$P(w_t|w_1,w_2,\\dots,w_{t-1})$ \n",
    "    - Example: Your smartphone's or Gmail's feature of next word(s) suggestion\n",
    "\n",
    "A model that computes either of these probabilities is called a _language model_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Language modeling: Why should we care?\n",
    "\n",
    "Powerful idea in NLP and helps in many tasks.\n",
    "- Machine translation \n",
    "    * P(In the age of data algorithms have the answer) > P(the age data of in algorithms answer the have)\n",
    "- Spelling correction\n",
    "    * My office is a 10  <span style=\"color:red\">minuet</span> bus ride from my home.  \n",
    "        * P(10 <span style=\"color:blue\">minute</span> bus ride from my home) > P(10 <span style=\"color:red\">minuet</span> bus ride from my home)\n",
    "- Speech recognition \n",
    "    * P(<span style=\"color:blue\">I read</span> a book) > P(<span style=\"color:red\">Eye red</span> a book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating probabilities of a sequence by applying chain rule \n",
    "\n",
    "Example: Suppose we want to calculate the probability of the following sequence of words: \n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\textrm{In the age of data algorithms have the answer}) =& P(\\textrm{In}) \\times P(\\textrm{the|In})\\\\ \n",
    "                                              & \\times P(\\textrm{age|In the}) \\times P(\\textrm{of|In the age})\\\\\n",
    "                                              & \\times P(\\textrm{data|In the age of})\\\\\n",
    "                                              & \\times P(\\textrm{algorithms|In the age of data}) \\\\\n",
    "                                              &  \\times P(\\textrm{have|In the age of data algorithms}) \\\\\n",
    "                                              & \\dots \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "- What if we just count occurrences to get conditional probabilities? \n",
    "- <span style=\"color:red\">BAD IDEA!!</span> The counts will be tiny and the model will be very sparse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Markov model of language\n",
    "\n",
    "When predicting future the past doesn't matter only the present. \n",
    "\n",
    "- Bigram language model\n",
    "    \n",
    "$$\n",
    "P(\\textrm{algorithms|In the age of data}) \\approx P(\\textrm{algorithms|data})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov model of language (bigram language model)\n",
    "\n",
    "- Use Markov assumption and calculate the probability of a sequence as follows!\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\textrm{In the age of data algorithms have the answer}) =& P(\\textrm{In}) \\times P(\\textrm{the|In})\\\\ \n",
    "                                              & \\times P(\\textrm{age|the})\\\\\n",
    "                                              & \\times P(\\textrm{of|age})\\\\\n",
    "                                              & \\times P(\\textrm{data|of})\\\\\n",
    "                                              & \\times P(\\textrm{algorithms|data}) \\\\                 \n",
    "                                              & \\times P(\\textrm{have|algorithms}) \\\\                             \n",
    "                                              & \\times P(\\textrm{the|have}) \\\\                                   \n",
    "                                              & \\times P(\\textrm{answer|the}) \\\\                                                                                 \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "### Estimating probabilities for the bigram language model\n",
    "\n",
    "- Example\n",
    "$$P(\\textrm{algorithms|data}) = \\frac{Count(\\textrm{data algorithms})}{Count(\\textrm{data})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Considering more history \n",
    "\n",
    "- Example: trigrams or four-gram language model\n",
    "    - Trigram language model\n",
    "$$\n",
    "P(\\textrm{algorithms|In the age of data}) \\approx P(\\textrm{algorithms|of data})\n",
    "$$\n",
    "    - Four-gram language model\n",
    "$$\n",
    "P(\\textrm{algorithms|In the age of data}) \\approx P(\\textrm{algorithms|age of data})\n",
    "$$\n",
    "\n",
    "\n",
    "- One way to deal with this is by making each state larger and applying the Markov framework we know well. \n",
    "    - **You will be doing this in the lab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Considering more history: Example \n",
    "\n",
    "Consider this corpus = {a rose is a rose}, Vocabulary size: $V = 3$\n",
    "\n",
    "- Word bigram model of language (n = 1)    \n",
    "    * Each state consists of a word (unigram) from the vocabulary. \n",
    "    * State space = {a, rose, is} ($3$ states)  \n",
    "    * Markov assumption: $P(s_{t+1}|s_0, \\dots s_t) = P(s_{t+1}|s_t)$ \n",
    "    * $P(\\text{rose|a rose is a}) = P(\\text{rose|a})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Considering more history: Example\n",
    "\n",
    "Consider this corpus = {a rose is a rose}, Vocabulary size: $V = 3$\n",
    "\n",
    "- Word trigram model of language (n = 2)\n",
    "    * Each state consists of a sequence of two words (bigrams) from the vocabulary. \n",
    "    * State space = {(a a), (a rose), (a is), (rose a), (rose rose), (rose is), (is a), (is rose), (is is)} ($3^2$ states)\n",
    "        - Many of these might not occur in the corpus\n",
    "    * Markov assumption: $P(s_{t+1}|s_0, \\dots s_t) = P(s_{t+1}|s_t)$ \n",
    "    * $P(\\text{(a rose)|(a rose), (rose is), (is a)}) = P(\\text{(a rose)}|\\text{(is a)})$\n",
    "    * What transitions are possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Google Ngram release (2006)\n",
    "\n",
    "- [All Our N-gram are Belong to You](https://ai.googleblog.com/2006/08/all-our-n-gram-are-belong-to-you.html)\n",
    "<blockquote>\n",
    "<p>Here at Google Research we have been using word n-gram models for a variety of R&D projects, such as statistical machine translation, speech recognition, spelling correction, entity detection, information extraction, and others.</p>\n",
    "<p>That's why we decided to share this enormous dataset with everyone. We processed 1,024,908,267,229 words of running text and are publishing the counts for all 1,176,470,663 five-word sequences that appear at least 40 times. There are 13,588,391 unique words, after discarding words that appear less than 200 times.</p>\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Are ngrams a good model of language?\n",
    "\n",
    "\n",
    "- In many cases, we can get by with ngram models. \n",
    "- But in general, is it a good assumption that the next word that I utter will be dependent on the last $n$ words?\n",
    "\n",
    "<blockquote>\n",
    "    The computer I was talking about yesterday when we were having dinner crashed. \n",
    "</blockquote>    \n",
    "\n",
    "- Language has long-distance dependencies.  \n",
    "- We can extend it to $3$-grams, $4$-grams, $5$-grams. But then there is sparsity problem. \n",
    "- Also, ngram models have huge RAM requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Language models with word embeddings\n",
    "\n",
    "- Ngram are great but we are representing context as the exact word.\n",
    "- Suppose in your training data you have the sequence \"feed the cat\" but you do not have the sequence \"feed the dog\".\n",
    "\n",
    "<blockquote>\n",
    "I have to make sure to feed the cat.\n",
    "</blockquote>\n",
    "\n",
    "- Trigram model: P(dog|feed the) = 0\n",
    "- If we represent words with embedding instead, we will be able to generalize to dog even if we haven't seen it in the corpus.\n",
    "- We'll come back to this when we learn about Recurrent Neural Networks (RNNs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Application3: PageRank\n",
    "- Graph-based ranking algorithm, which assigns a rank to a webpage.\n",
    "- The rank indicates a relative score of the page's importance and authority.\n",
    "- Intuition\n",
    "    - Important webpages are linked from other important webpages.\n",
    "    - Don't just look at the number of links coming to a webpage but consider who the links are coming from \n",
    "<img src=\"files/images/wiki_page_rank.jpg\" height=\"500\" width=\"500\"> \n",
    "\n",
    "[Credit](https://en.wikipedia.org/wiki/PageRank#/media/File:PageRanks-Example.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### PageRank: scoring\n",
    "\n",
    "- Imagine a browser doing a random walk \n",
    "    - At time t=0, start at a random webpage.\n",
    "    - At time t=1, follow a random link on the current page.\n",
    "    - At time t=2, follow a random link on the current page. \n",
    "    \n",
    "- Intuition\n",
    "    - In the \"steady state\" each page has a long-term visit rate, which is the page's score (rank). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PageRank as a Markov chain\n",
    "\n",
    "- A state is a web page\n",
    "- Transition probabilities represent probabilities of moving from one page to another\n",
    "- We derive these from the adjacency matrix of the web graph\n",
    "    - Adjacency matrix $M$ is a $n \\times n$ matrix, if $n$ is the number of states (web pages)\n",
    "    - $M_{ij} = 1$ if there is a hyperlink from page $i$ to page $j$.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculate page rank: power iteration method\n",
    "\n",
    "- Start with a random initial probability distribution $\\pi_0$\n",
    "- Multiply $\\pi_0$ by powers of the transition matrix $T$ until the product looks stable \n",
    "    - After one step, we are at $\\pi T$\n",
    "    - After two steps, we are at $\\pi T^2$\n",
    "    - After three steps, we are at $\\pi T^3$\n",
    "    - Eventually (for a large $k$), $\\pi T^k = \\pi$ \n",
    "    \n",
    "    \n",
    "#### Want to know more details? \n",
    "\n",
    "- Check out lecture4 from last year in the archive folder.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- A discrete Markov chain is a random process that has \n",
    "    * a set of finite states \n",
    "    * an initial probability distribution over states\n",
    "    * transition probability matrix\n",
    "- We can do a number of things with Markov chains\n",
    "    - Generate a sequence of states. \n",
    "    - Calculate the probability of a sequence.  \n",
    "    - Compute the probability of being in a particular state at time $t$. \n",
    "    - Calculate stationary distribution which is a probability distribution that remains unchanged in the Markov chain as time progresses. \n",
    "- Example applications of Markov chains in NLP\n",
    "    - Language modeling\n",
    "    - PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other fun things with Markov chains \n",
    "\n",
    "- [Create and visualize Markov chains](https://www.stat.auckland.ac.nz/~wild/MarkovChains/)\n",
    "- [Markov chains \"explained visually\"](http://setosa.io/ev/markov-chains)\n",
    "- [Snakes and ladders](http://datagenetics.com/blog/november12011/index.html)\n",
    "- [Candyland](http://www.datagenetics.com/blog/december12011/index.html)\n",
    "- [Yahtzee](http://www.datagenetics.com/blog/january42012)\n",
    "- [Chess pieces returning home and K-pop vs. ska](https://www.youtube.com/watch?v=63HHmjlh794)\n",
    "- [The Life and Work of A. A. Markov](http://www.meyn.ece.ufl.edu/archive/spm_files/Markov-Work-and-life.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
