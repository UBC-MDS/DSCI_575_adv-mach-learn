{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 575 - Advanced Machine Learning\n",
    "\n",
    "# Lab 3: HMMs and Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim \n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from gensim import matutils, models\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Submission guidelines](#sg)\n",
    "- [Learning outcomes](#lo)\n",
    "- [Exercise 1: Hidden Markov models (HMMs) by hand](#hmm)\n",
    "- [Exercise 2: Topic modeling with LDA](#lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission guidelines <a name=\"sg\"></a>\n",
    "\n",
    "#### Tidy submission\n",
    "rubric={mechanics:2}\n",
    "- To submit this assignment, submit this jupyter notebook with your answers embedded.\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- Use proper English, spelling, and grammar throughout your submission.\n",
    "\n",
    "#### Code quality and writing\n",
    "- These rubrics will be assessed on a question-by-question basis and are included in individual question rubrics below where appropriate.\n",
    "- See the [quality rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_quality.md) and [writing rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_writing.md) as a guide to what we are looking for.\n",
    "- Refer to [Python PEP 8 Style Guide](https://www.python.org/dev/peps/pep-0008/) for coding style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes <a name=\"lo\"></a>\n",
    "\n",
    "After finishing this lab you will be able to \n",
    "- formulate an HMM for part-of-speech tagging\n",
    "- prepare data for topic modeling\n",
    "- build a topic model using `gensim`\n",
    "- interpret and visualize your topic model\n",
    "- evaluate your topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Hidden Markov models (HMMs) by hand <a name=\"hmm\"></a>\n",
    "\n",
    "We saw the Viterbi algorithm for hidden Markov models (HMMs) in class. In general, it's a useful algorithm to know, as it can be used to find the most likely assignment of all or some subset of latent variables in graphical models such as hidden Markov models, Bayesian networks and conditional random fields. Recently, it has been used in conjunction with deep learning approaches. (For example, see [Le et al. 2017](https://aclweb.org/anthology/P17-1044).)\n",
    "\n",
    "In this exercise, you will be working through the Viterbi algorithm by hand on a toy data to do part-of-speech tagging. Recall that part-of-speech tagging is the problem of assigning part-of-speech tags to each word in a given text. Usually, given a raw text corpus, only the words are observable and the part-of-speech tags are \"hidden\" and HMM is a natural choice for this problem. In fact, it used to be a popular model for the problem but the current state-of-the-art approach is a deep-learning approach. See [here](https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art)) for the current state-of-the-art for part-of-speech tagging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(a) \n",
    "rubric={reasoning:4}\n",
    "\n",
    "Consider the sentence below:\n",
    "<blockquote>\n",
    "    Will the chair chair the meeting from this chair ?\n",
    "</blockquote>\n",
    "\n",
    "and a simple part-of-speech tagset: \n",
    "<blockquote>\n",
    "{noun, verb, determiner, preposition, punctuation}\n",
    "</blockquote>    \n",
    "\n",
    "The table below shows the possible assignments for words and part-of-speech tags. The symbol `x` denotes that the word and part-of-speech tag combination is possible. For instance, the word _chair_ is unlikely to be used as a determiner and so we do not have an `x` there. \n",
    "\n",
    "|    <i></i>    | Will    | the     | chair   | chair   | the     | meeting  | from    | this    | chair   | ?       |\n",
    "| ------------- | :-----: | :-----: | :-----: | :-----: | :----:  | :------: | :-----: | :-----: | :-----: | :----:  |\n",
    "| noun          | x       | x       |  x      | x       | x       | x        | <i></i> | <i></i> | x       | <i></i> |\n",
    "| verb          | x       | <i></i> |  x      | x       | <i></i> | x        | <i></i> | <i></i> | x       | <i></i> |\n",
    "| determiner    | <i></i> | x       | <i></i> | <i></i> | x       | <i></i>  | <i></i> | x       | <i></i> | <i></i> |\n",
    "| preposition   | <i></i> | <i></i> | <i></i> | <i></i> | <i></i> | <i></i>  | x       | <i></i> | <i></i> | <i></i> |\n",
    "| punctuation   | <i></i> | <i></i> | <i></i> | <i></i> | <i></i> | <i></i>  | <i></i> | <i></i> | <i></i> | x       |\n",
    "\n",
    "\n",
    "Given this information, answer the following questions: \n",
    "1. With this simple tagset of part-of-speech tags, how many possible part-of-speech tag sequences (i.e, hidden state sequences) are there for the given sentence (observation sequence)?\n",
    "2. Restricting to the possibilities shown above with `x`, how many possible part-of-speech tag sequences are there?\n",
    "3. Given an HMM with states as part-of-speech tags and observations as words, one way to decode the observation sequence is as follows: \n",
    "    - enumerate all possible hidden state sequences (i.e., enumerate all solutions)\n",
    "    - for each hidden state sequence, calculate the probability of the observation sequence given the hidden state sequence (i.e., score each solution)\n",
    "    - pick the hidden state sequence which gives the highest probability for the observation sequence (i.e., pick the best solution)\n",
    "    \n",
    "   What is the time complexity of this method in terms of the number of states ($N$) and the length of the output sequence ($T$)?\n",
    "   \n",
    "4. If you decode the sequence using the Viterbi algorithm instead, what will be the time complexity in terms of the number of states ($N$) and the length of the output sequence ($T$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(b) \n",
    "rubric={reasoning:5}\n",
    "\n",
    "Consider a two word language _fish_ and _sleep_ with two possible part-of-speech tags: _noun_ and _verb_. Suppose in our training corpus, _fish_ appears 8 times as a noun and 5 times as a verb and _sleep_ appears 2 times as a noun and 5 times as a verb. The probability of a sentence starting with a noun is 0.8 and with a verb 0.2. The state transitions between noun and verb are shown in the picture below. Note that we have one extra state in the picture below, with the label 'End'. We have this state as an \"accepting\" state; we do not have any transitions from this state. We have added this state to make the transition probabilities work. Include it in the transition matrix. But do not include it in the emission probabilities or when you run the Viterbi algorithm in the next exercise. \n",
    "\n",
    "<center>\n",
    "<img src=\"HMM_POS_tagging.png\" width=\"400\" height=\"400\">\n",
    "</center>  \n",
    "\n",
    "Your task: \n",
    "\n",
    "Define a hidden Markov model for part-of-speech tagging for this language. In particular, specify \n",
    "1. the set of states\n",
    "2. the set of output alphabet\n",
    "3. the initial state discrete probability distribution\n",
    "4. the transition probability matrix\n",
    "5. the emission probabilities. \n",
    "\n",
    "(Credit: This idea of a two word language with the words _fish_ and _sleep_ is [Ralph Grishman](https://cs.nyu.edu/grishman/)'s idea.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 1(c) Find the best part-of-speech tag sequence\n",
    "rubric={reasoning:1}\n",
    "\n",
    "- Run the Viterbi algorithm to find the best part-of-speech sequence for the observed sequence **fish fish sleep**. In particular, calculate $\\delta$ and $\\psi$ at each state for each time step and then find the globally optimal sequence of tags for the observed sequence **fish fish sleep**. Show your work. (You may copy the latex code from the lecture notes. That said, if you do not feel like typing all this in Markdown, you may do this on paper, take a picture, and upload an image here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Topic modeling with LDA <a name=\"lda\"></a>\n",
    "\n",
    "In this exercise you will explore the topics in `scikit-learn`'s [20 newsgroups text dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) using [`gensim`'s `ldamodel`](https://radimrehurek.com/gensim/models/ldamodel.html). Usually, topic modeling is used for discovering the abstract \"topics\" that occur in a collection of documents when you do not know the actual topics present in the documents. But since 20 newsgroups text dataset is labeled with categories (e.g., sports, hardware, religion), you will be able to cross-check the topics discovered by your model with the actual topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and examine the first few rows. Note that we won't be violating the golden rule by looking at the training subset; later we will be using a separate test subset to evaluate the model. \n",
    "\n",
    "Below I am giving you starter code to load the train and test portion of the data and convert the train portion into a pandas DataFrame. Note that we are using train and test splits so that we can later examine how well the LDA model we learn is able to assign topics to unseen documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "data = {'text':[], 'target_name':[], 'target':[]}\n",
    "data['text'] = newsgroups_train.data\n",
    "data['target_name'] = [newsgroups_train.target_names[target] for target in newsgroups_train.target]\n",
    "data['target'] = [target for target in newsgroups_train.target]\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) Preprocessing\n",
    "rubric={accuracy:4,quality:1,reasoning:2}\n",
    "\n",
    "We want our topic model to identify interesting and important patterns. For that we need to \"normalize\" our text. Preprocessing is a crucial step before you train an LDA model and it markedly affects the results. In this exercise you'll prepare the data for topic modeling. We have been using `nltk` for preprocessing so far. In this lab, we will use another popular Python NLP library called [spaCy](https://spacy.io/), which we briefly discussed in Lecture 2. Install the library and the models for English using the following commands. You can find more information about the installation [here](https://spacy.io/usage).\n",
    "\n",
    "`conda install -c conda-forge spacy`\n",
    "\n",
    "`python -m spacy download en_core_web_sm`\n",
    "\n",
    "spaCy is a powerful library and it can do many other things, but we'll be using it for preprocessing.  With this library, you can run the NLP pipeline by simply calling the function `nlp`. You can then access information about each token in a `for` loop as shown below. \n",
    "\n",
    "```\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.pos_)\n",
    "    print(token.lemma_)\n",
    "```\n",
    "\n",
    "Your task is to complete the function `preprocess` below to carry out preprocessing. In particular, \n",
    "\n",
    "1. Get rid of email addresses and other weird characters and patterns.  \n",
    "2. Replace multiple spaces with a single space. \n",
    "3. Run NLP analysis using `spaCy` and exclude tokens \n",
    "    - which are stop words.\n",
    "    - which have length < `min_token_len`.\n",
    "    - which have irrelevant part-of-speech tags as given in `irrelevant_pos`. [Here](https://spacy.io/api/annotation/#pos-en) is the list of part-of-speech tags used by spaCy. \n",
    "4. Get lemma of each token, which is the root form of a word. You can access it using `token.lemma_` \n",
    "5. Carry out other preprocessing, if necessary. \n",
    "6. Return the preprocessed text.  \n",
    "\n",
    "**Note that preprocessing the corpus might take time.** So here are a couple of suggestions:\n",
    "- During the debugging phase, work on a smaller subset of the data. \n",
    "- You might want to add an extra column in your dataframe for preprocessed text and save the dataframe as a CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "import spacy\n",
    "# Load English model for SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "def preprocess(text, \n",
    "               min_token_len = 2, \n",
    "               irrelevant_pos = ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']): \n",
    "    \"\"\"\n",
    "    Given text, min_token_len, and irrelevant_pos carry out preprocessing of the text \n",
    "    and return a preprocessed string. \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (str) \n",
    "        the text to be preprocessed\n",
    "    min_token_len : (int) \n",
    "        min_token_length required\n",
    "    irrelevant_pos : (list) \n",
    "        a list of irrelevant pos tags\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    (str) the preprocessed text\n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n",
    "### END STARTER CODE    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b) Build dictionary and document-term co-occurrence matrix\n",
    "rubric={accuracy:2,quality:1}\n",
    "\n",
    "We need two things to build `gensim`'s `LdaModel`: a dictionary and a document-term co-occurrence matrix. In this exercise, you'll\n",
    "\n",
    "1. Create a dictionary using `gensim`'s [`corpora.Dictionary`](https://radimrehurek.com/gensim/corpora/dictionary.html) method. \n",
    "2. Create the document-term co-occurrence matrix using `corpora.Dictionary`'s `doc2bow` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(c): Build a topic model\n",
    "rubric={accuracy:4,reasoning:2}\n",
    "\n",
    "In this exercise you will build an LDA topic model on the prepared data.  \n",
    "\n",
    "1. Build an LDA model using `gensim`'s [`models.LdaModel`](https://radimrehurek.com/gensim/models/ldamodel.html) with `num_topics` = 5. Note: If you get many warning when you build your model, update your gensim installation.  See [here](https://github.com/RaRe-Technologies/gensim/pull/2296).\n",
    "2. Print LDA topics with the `model.print_topics()` methods, where `model` is your LDA model. \n",
    "3. Experiment with a few choices of the `num_topics` and `passes` hyperparameters. \n",
    "4. Settle on the hyperparameters where the topics make sense to you and briefly explain your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(d) Visualization and interpretation\n",
    "rubric={viz:2,reasoning:4}\n",
    "\n",
    "Once you settle on the number of topics and passes, visualize the topics and interpret them. In particular,  \n",
    "\n",
    "1. Visualize the topics using [pyLDAvis](https://github.com/bmabey/pyLDAvis), which is a Python library for interactive topic model visualization. Note: Use `sort_topics=False`. Otherwise the topic ids in the previous exercise won't match with the topics here.\n",
    "2. Using the words in each topic and their corresponding weights, manually assign a label (e.g., *sports, politics, religion*) to each topic based on the common theme in the most probable words in that topic.\n",
    "3. Create a dictionary named `topic_labels` with keys as the topic id and your manually-assigned topic label as the values. An example key-value pair in the dictionary is shown in the starter code below. (Of course in your topic model the topic with id 0 might not be 'Science and technology'. I am just showing you an example here.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "topic_labels = {0:'Science and technology'}\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(e) Test on unseen documents \n",
    "rubric={accuracy:4,quality:2,reasoning:2}\n",
    "\n",
    "In this particular data, we already know the \"topics\" (labels) for each article. In this exercise, you will examine to what extent the topics identified by the LDA model match with the actual labels of unseen documents. I am giving you starter code to create a DataFrame for the test data. \n",
    "\n",
    "Your tasks:\n",
    "1. Complete the function `get_topic_label_prob` below which takes an unseen document and the model as input and returns a string of the form `most likely topic label:probability of the label` (e.g., 'Science and Technology:0.435'). Hint: You can access the topic assignment of the unseen document using `lda[bow_vector]`, where `lda` is your lda model and `bow_vector` is the bow vector created using `dictionary.doc2bow`. \n",
    "2. Call `get_most_prob_topic` for each document (i.e., each cell in the `text` column) in `sample_test_df`. \n",
    "3. For around 10 to 20 documents, manually examine their gold labels (`target_name`) and LDA assigned topics. Comment on whether the LDA topic assignments make sense or not and to what extent topic assignments match with the corresponding values in the `target_names` column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "data = {'text':[], 'target':[]}\n",
    "data['text'] = newsgroups_test.data\n",
    "data['target_name'] = [newsgroups_test.target_names[target] for target in newsgroups_test.target]\n",
    "data['target'] = [target for target in newsgroups_test.target]\n",
    "test_df = pd.DataFrame(data)\n",
    "sample_test_df = test_df.sample(100)\n",
    "sample_test_df\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "def get_most_prob_topic(unseen_document, model = lda):\n",
    "    \"\"\"\n",
    "    Given an unseen_document, and a trained LDA model, this function\n",
    "    finds the most likely topic (topic with the highest probability) from the \n",
    "    topic distribution of the unseen document and returns the best topic with \n",
    "    its probability. . \n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    unseen_document : (str) \n",
    "        the document to be labeled with a topic\n",
    "    model : (gensim ldamodel) \n",
    "        the trained LDA model\n",
    "    \n",
    "    Returns: \n",
    "    -------------\n",
    "        (str) a string of the form \n",
    "        `most likely topic label:probability of that label` \n",
    "    \n",
    "    Examples:\n",
    "    ----------\n",
    "    >> get_most_prob_topic(\"The research uses an HMM for discovering gene sequence.\", \n",
    "                            model = lda)\n",
    "    Science and Technology:0.435\n",
    "    \"\"\"    \n",
    "### END STARTER CODE    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
