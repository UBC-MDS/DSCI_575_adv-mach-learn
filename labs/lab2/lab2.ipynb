{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 575 - Advanced Machine Learning\n",
    "\n",
    "# Lab 2: Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [Submission guidelines](#sg)\n",
    "- [Learning outcomes](#lo)\n",
    "- [Exercise 1: Warm-up](#wu)\n",
    "- [Exercise 2: Character-based Markov model of language](#mmch)\n",
    "- [Exercise 3: Stationary distribution and other fun stuff](#sd)\n",
    "- [Exercise 4: Word-based Markov model of language](#mmw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission guidelines <a name=\"sg\"></a>\n",
    "\n",
    "#### Tidy submission\n",
    "rubric={mechanics:2}\n",
    "- To submit this assignment, submit this jupyter notebook with your answers embedded.\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- Use proper English, spelling, and grammar throughout your submission.\n",
    "\n",
    "#### Code quality and writing\n",
    "- These rubrics will be assessed on a question-by-question basis and are included in individual question rubrics below where appropriate.\n",
    "- See the [quality rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_quality.md) and [writing rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_writing.md) as a guide to what we are looking for.\n",
    "- Refer to [Python PEP 8 Style Guide](https://www.python.org/dev/peps/pep-0008/) for coding style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes <a name=\"lo\"></a>\n",
    "\n",
    "After working on this lab, you will be able to\n",
    "\n",
    "- Build a character-based Markov model of language. \n",
    "- Explain states, state space, and transition matrix in Markov models of language. \n",
    "- Explain and calculate stationary distribution over states in Markov models of language. \n",
    "- Calculate the probability of patterns using Markov models of language. \n",
    "- Build a word-based Markov model of language and generate text using this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Warm-up <a name=\"wu\"></a>\n",
    "\n",
    "This exercise will get you thinking about how to generate text using Markov models. You will build a simple Markov model with a tiny corpus, where the current letter only depends upon the previous letter ($n=1$).  \n",
    "\n",
    "Below I am providing you some starter code to create bigram frequency counts of letters in a tiny corpus with 6 words. Our goal is to build a Markov model with this corpus, where the set of states is the unique letters in the corpus.  \n",
    "\n",
    "Note: Recall that in DSCI 512 lab1, Exercise 4, you implemented a Markov model of language and generated text  (without actually knowing the details about the model). You pre-computed the frequencies for every possible $n$ gram as follows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "corpus = 'to be or not to be'\n",
    "n = 1\n",
    "circ_corpus = corpus + corpus[:n]\n",
    "frequencies = defaultdict(Counter)\n",
    "for i in range(len(circ_corpus) - n):\n",
    "    frequencies[circ_corpus[i:i + n]][circ_corpus[i + n]] += 1\n",
    "frequencies    \n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(a) Visualizing character bigram counts as a co-occurrence matrix\n",
    "rubric={viz:2} \n",
    "\n",
    "Now let's try to visualize the bigram frequency counts calculated above as a pandas DataFrame. \n",
    "\n",
    "Your task:\n",
    "\n",
    "- Show the bigram frequencies in `frequencies` variable above as a pandas DataFrame, sorting the column and row labels alphabetically, where s\n",
    "    * column labels and row indices are unique characters in the corpus, and \n",
    "    * the value in each cell $a_{ij}$ represents how often the character $j$ is followed by character $i$ in our corpus.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(b) Transition matrix\n",
    "rubric={accuracy:3,viz=1}\n",
    "\n",
    "Given the frequencies in 1(a), let's compute the transition matrix (i.e., the conditional probability distribution for every possible $n$ gram). \n",
    "\n",
    "1. Normalize each row in the above matrix so that each row sums to 1.0.\n",
    "2. Visualize this normalized matrix as a pandas DataFrame. Now you have the transition matrix of your Markov model! \n",
    "3. How many unique states are there in your Markov model? \n",
    "\n",
    "Recall that the transition matrix $T$ is a square matrix and the number of rows/columns is equal to the number of states. Each row is a discrete probability distribution summing to 1. The element $T_{ij}$ is the probability of transitioning from state $i$ to state $j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c) Probability of sequences\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Suppose the probability of starting a sequence with letter $b$ is $0.4$.Given the transition matrix in 1(b), what are the probabilities of the following sequences?\n",
    "    * be or\n",
    "    * beet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(d) Generate sequences\n",
    "rubric={reasoning:2}\n",
    "\n",
    "- Given the transition matrix above, explain in words how would you generate a sequence of length `seq_len` given the start symbol `t`. You don't have to, but you are welcome to write the code for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Character-based Markov model of language <a name=\"mmch\"></a>\n",
    "\n",
    "Recall Exercise 4: Markov Model of language from DSCI 512 lab1. In this exercise, you wrote a class `MarkovModel`\n",
    " to `fit` an n-gram Markov model and generated text. Now that you know what Markov models are, we will start with what you did in DSCI 512 lab1 and build on it. \n",
    "\n",
    "The starter code below uses the hyperparameter $n$, where our \"state\" of the Markov chain is the last $n$ characters of a give string. In Exercise 1, we worked with $n = 1$ and our \"state\" of the Markov chain was a single character and each character was dependent on the last one character. When $n=3$, it means that the probability distribution over the _next character_ only depends on the _preceding 3 characters_. We use the name [_n-gram_](https://en.wikipedia.org/wiki/N-gram) for a sequence of $n$ characters.\n",
    "\n",
    "We train our model from data by recording every occurrence of every $n$-gram and, in each case, recording what the next letter is. Then, for each $n$-gram, we normalize these counts into probabilities just like we did with naive Bayes. The `fit` function below implements these steps.\n",
    "\n",
    "To generate a new sequence, we start with some initial seed of length $n$ (here, we will just use the first $n$ characters in the training text, which are saved at the end of the `fit` function). Then, for the current $n$-gram we will look up the probability distribution over next characters and sample a random character according to this distribution.\n",
    "\n",
    "Attribution: assignment adapted with permission from Princeton COS 126, [_Markov Model of Natural Language_]( http://www.cs.princeton.edu/courses/archive/fall15/cos126/assignments/markov.html). Original assignment was developed by Bob Sedgewick and Kevin Wayne. If you are interested in more background info, you can take a look at the original version. The original paper by Shannon, [A Mathematical Theory of Communication](http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf), essentially created the field of information theory and is, in my opinion, one of the best scientific papers ever written (in terms of both impact and readability).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "class MarkovModel():\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        n -- (int) \n",
    "            the size of the ngram\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "    \n",
    "    def fit(self, text):\n",
    "        \"\"\"        \n",
    "        Fit a Markov chain and create a transition matrix.\n",
    "        Arguments:\n",
    "        text -- (str) \n",
    "            text to fit the Markov chain         \n",
    "        \"\"\"\n",
    "        # make text circular so markov chain doesn't get stuck\n",
    "        circ_text = text + text[:self.n] \n",
    "        \n",
    "        # count the number of occurrences of each letter following a given n-gram\n",
    "        frequencies = defaultdict(Counter)\n",
    "        for i in range(len(text)):\n",
    "            frequencies[circ_text[i:i+self.n]][circ_text[i+self.n]] += 1.0\n",
    "            \n",
    "        # normalize the frequencies into probabilities (separately for each n-gram)\n",
    "        self.probabilities_ = defaultdict(dict)\n",
    "        for ngram, counts in frequencies.items():            \n",
    "            self.probabilities_[ngram][\"symbols\"] = list(counts.keys())            \n",
    "            probs = np.array(list(counts.values()))\n",
    "            probs /= np.sum(probs)\n",
    "            self.probabilities_[ngram][\"probs\"] = probs \n",
    "        \n",
    "        # store the firstnk characters of the training text, as we will use these\n",
    "        # to seed our `generate` function\n",
    "        self.starting_chars = text[:self.n]\n",
    "        self.frequencies_ = frequencies # you never know when this might come in handy\n",
    "   \n",
    "    def generate(self, seq_len):\n",
    "        '''\n",
    "        Using self.starting_chars, generate a sequence of length seq_len \n",
    "        using the transition matrix created in the fit method.\n",
    "\n",
    "        Arguments:\n",
    "        seq_len -- (int) \n",
    "            the desired length of the sequence\n",
    "\n",
    "        Returns:\n",
    "        (str) The generated sequence\n",
    "        '''                \n",
    "        # YOUR CODE HERE\n",
    "        # BEGIN SOLUTION \n",
    "        s = self.starting_chars\n",
    "        while len(s) < seq_len:\n",
    "            probs = self.probabilities_[s[-self.n:]]\n",
    "            s += npr.choice(probs[\"symbols\"], p=probs[\"probs\"])\n",
    "        return s    \n",
    "### END STARTER CODE    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "# Let's test our code. \n",
    "data_url = 'http://www.gutenberg.org/files/2591/2591-0.txt'\n",
    "corpus = urlopen(data_url).read().decode(\"utf-8\")\n",
    "corpus = corpus[2000:]\n",
    "model = MarkovModel(n=5)\n",
    "model.fit(corpus)\n",
    "print(model.generate(500))\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $n$ gets larger the output makes more sense. Around $n=5$ it looks like English. Around $n=15$ it look like it's memorizing the training set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) \"Circular\" version of the text\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Why do we need to use a \"circular\" version of the text in the `fit` function? What could go wrong if we didn't do that, and instead used the original `text` (insetad of `circ_text`) and made the loop \n",
    "```\n",
    "for i in range(len(text)-self.n):\n",
    "```\n",
    "which allow `fit` to run without crashing?\n",
    "\n",
    "Hint: the problem would arise during `generate`, not during `fit`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b) Smoothing\n",
    "rubric={reasoning:2}\n",
    "\n",
    "The description above mentioned a connection to naive Bayes. When discussing naive Bayes we briefly mentioned [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing). Is there something analogous to Laplace smoothing that we could do here? If so, describe what it would entail and what effect it would have. (You don't have to implement it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(c) States, state space, and transition matrix\n",
    "rubric={reasoning:10}\n",
    "\n",
    "Let's consider the Markov chain interpretation of what we've just done. Let's define a state as the previous $n$ characters \"emitted\" by our chain. Let's assume our vocabulary size (the number of possible characters) is $V$; for example, $V=26$ if we were only using lowercase letters. We can compute this in our case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size = %d\" % len(np.unique(list(corpus))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's just stick with a general $V$ for now. Call the number of possible states $S$. Let's consider the _transition matrix_ $T$ of this Markov chain. The transition matrix is a square matrix and the number of rows/columns is equal to the number of states, so in our case it is $S \\times S$. Each row is a discrete probability distribution summing to 1. The element $T_{ij}$ is the probability of transitioning from state $i$ to state $j$. \n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. What is the number of possible states, $S$, in terms of $V$ and $n$? (You might not encounter all these states in practice, if not all $n$-grams appear in the training data, but let's ignore that for now.)\n",
    "2. Give two examples states in the state space for $n=3$.\n",
    "3. In our application above when $n>1$ _not all transitions are possible_. This means $T$ will contain a bunch of zeros. Why?\n",
    "4. Again for $n>1$ what is the maximum number of nonzero elements that $T$ could have? Answer in terms of $V$ and $n$. \n",
    "5. Is the state space discrete or continuous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Stationary distribution and other fun stuff <a name=\"sd\"></a>\n",
    "\n",
    "The code below computes the transition matrix for you, for the Shakespeare data with $n=1$. Consider this transition matrix for the next few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE \n",
    "data_url = 'http://www.gutenberg.org/files/100/100-0.txt'\n",
    "shakespeare_text = urlopen(data_url).read().decode(\"utf-8\")\n",
    "shakespeare_text = shakespeare_text[4000:]\n",
    "### END STARTER CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE \n",
    "states = np.unique(list(shakespeare_text))\n",
    "print(\"States:\", states)\n",
    "S = len(np.unique(list(shakespeare_text)))\n",
    "print(\"Number of states:\", S)\n",
    "\n",
    "model = MarkovModel(n=1)\n",
    "model.fit(shakespeare_text)\n",
    "\n",
    "# implementation note: since len(model.probabilities_[state][\"probs\"]) might not equal S\n",
    "# for all letters, we need to be careful and do a reverse-lookup for the actual letters\n",
    "# the rest of the transition probabilities are just zero (if they don't appear)\n",
    "lookup = dict(zip(states, list(np.arange(S, dtype=int))))\n",
    "\n",
    "T = np.zeros((S,S)) # transition matrix\n",
    "for i,state in enumerate(states):\n",
    "    for j, letter in enumerate(model.probabilities_[state][\"symbols\"]):\n",
    "        T[i, lookup[letter]] = model.probabilities_[state][\"probs\"][j]\n",
    "# print(T)\n",
    "print(\"Number of nonzero transition probabilities: %d/%d\" % (np.sum(T>0), T.size))\n",
    "### END STARTER CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(a) Stationary distribution conditions \n",
    "rubric={reasoning:4}\n",
    "\n",
    "Under mild assumptions, a Markov chain has a _stationary distribution_ which is the probability of finding yourself in each state after the chain is run for a long time. These assumptions are:\n",
    "\n",
    "- \"Irreducible\" (doesn’t get stuck in part of the graph)\n",
    "- \"Aperiodic\" (doesn’t keep repeating same sequence).\n",
    "\n",
    "Give a short explanation for why our Markov chain satisfies these assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(b) Stationary distribution for the `shakespeare_text`\n",
    "rubric={accuracy:5}\n",
    "\n",
    "It's not true in general but in this particular case we actually already know the stationary distribution -- it is just the relative frequency that these $n$-grams occur in the training data (you are welcome to think about this deeply, but you don't have to). (Recall that we are assuming n=1 here.)\n",
    "\n",
    "Your tasks: \n",
    "\n",
    "1. Calculate the stationary distribution for the `shakespeare_text` by calculating the relative frequencies for each n-gram (i.e., state) in the corpus. In particular, for each n-gram or state $s_i$ you can calculate $P(s_i)$ by counting the number of occurrences of the state $s_i$ in the corpus and divide it by the total number of n-grams in the corpus, similar to how Andrey Markov calculated stationary distribution for vowels and consonants in his corpus.\n",
    "2. Show empirically that this is a stationary distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 3(c) Stationary distribution using eigenvalue decomposition\n",
    "rubric={reasoning:1}\n",
    "\n",
    "You can compute the stationary distribution in another ways. \n",
    "\n",
    "1. Calculate stationary distribution using eigenvalue decomposition of the transition matrix. \n",
    "2. Compare your result from part 3(b) with the result below. Do they agree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(d) Finding probability of occurrences of patterns \n",
    "rubric={reasoning:6}\n",
    "\n",
    "Let's consider the conditional probability that a lower case vowel comes 3 characters later given that the current letter is \"a\". In other words, we're searching for the pattern `axxv` where `v` is a lower case vowel (defined as a,e,i,o,u,y) and `x` is any character and `a` is literally \"a\". \n",
    "\n",
    "Let's use $n=1$.\n",
    "\n",
    "1. It turns out we can estimate this probability directly from the transition matrix. While $T$ gives us the probabilities one step ahead, $T\\times T$ gives us the probabilities 2 steps ahead, etc. (If you want to think about this, you should be able to convince yourself it's true by contemplating what matrix multiplication really means, but this is optional.) So, taking $T^3$ gives us the transition probabilities for 3 steps later. Compute $T^3$ and find the estimated probability that we're looking for. Note: you should NOT use `T**3`, as that is elementwise exponentiation rather than a matrix power. You can get $T^3$ using `numpy.linalg.matrix_power(T,3)` or just `T@T@T`.\n",
    "2. We could also estimate this probability directly from the data, by just seeing how frequently this pattern occurs. Do this. How well does it match your above results? What does this have to do with the quality of our Markov assumption?\n",
    "3. What if we increased $n$ and repeated part (1), would you expect to get closer to the answer from part (2)? You are welcome to try this but you don't have to - the goal is just to think about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A close match. This means the Markov assumption is working reasonably well for this problem. It doesn't mean that the output looks like text though! It just means the assumptions in the Markov chain are doing a reasonably good job of capturing this particular conditional probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Markov model of language with words <a name=\"mmw\"></a>\n",
    "\n",
    "In this exercise we'll continue with the Markov model of language, but we'll work with _words_ instead of _characters_. The `MarkovModel` code stays the same. Just remember that now we are dealing with words and not characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we say $n$-gram we're now referring to the last $n$ words, not the last $n$ characters. In general, the term $n$-gram can refer to characters or word; see the [Wikipedia article](https://en.wikipedia.org/wiki/N-gram).\n",
    "\n",
    "One concern with words is that, in a sense, we have less data to work with. For example with characters and $n=3$ we have a lot of examples of seeing the character combination \"per\" and checking what character follows it, but with words even with $n=1$ (the smallest nontrivial value of $n$) we might only have one example of the word \"persuade\" in our corpus. You can imagine that the number of \"training examples\" only gets smaller if $n>1$. This is something to keep in mind when deciding what values of $n$ might be reasonable.\n",
    "\n",
    "Another issue is how to deal with punctuation. How do we define a word exactly? We will use the standard convention that punctuation characters are considered separate words. To accomplish this preprocessing, we will use the popular python package [NLTK](http://www.nltk.org/) (Natural Language ToolKit), which we have seen in class. You should be able to install it with\n",
    "\n",
    "```\n",
    "conda install nltk\n",
    "```\n",
    "Afterwards, you'll need to install the NLTK data files (these are often natural-language-specific). You can grab the tokenizer we need with\n",
    "```\n",
    "python -m nltk.downloader 'punkt'\n",
    "```\n",
    "If you end up using NLTK for other stuff later on, you can download the rest of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4(a) Word-based n-gram language model\n",
    "rubric={accuracy:4,quality:2,reasoning:2}\n",
    "\n",
    "The first step is to break apart the text string into words. NLTK's `word_tokenize` will turn our text into a lists of \"tokens\" which we will use as our language \"atoms\". This tokenizing process removes whitespace. So, in `generate`, you should add a space character back in between tokens. This won't look quite right, but it's good enough for now.\n",
    "\n",
    "Your tasks:\n",
    "1. Use NLTK for word tokenization. \n",
    "2. Implement a word-based Markov model of language.\n",
    "3. Compare it to your character-based model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional note: only the `generate` function needs to be rewritten, and, even there, the required modifications are not large. I don't think we talked about class inheritance in DSCI 524 (right?), but it's a handy trick. The line\n",
    "```\n",
    "class MarkovModelWords(MarkovModel):\n",
    "```\n",
    "defines a new class called `MarkovModelWords` that you can think of as an offspring of `MarkovModel`. It \"inherits\" all the functions from `MarkovModel` unless we explicitly overwrite them. So, if you implement `generate` in the class `MarkovModelWords`, the old `generate` funtion will be overwritten but all the other functions will persist. \n",
    "\n",
    "But, if you're not comfortable with inheritance, or just don't feel like it, you're completely welcome to just modify the above code and not use inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another note: the way `MarkovModel` is implemented, the patterns we're conditioning on (the last $n$ characters/words) are used as keys in python dictionaries. For characters that was easy because we could just use a string as a key. However, for words with $n>1$ we now have a collection of words, and we want to use this as a dict key. `nltk.tokenize.word_tokenize` outputs a list, which can't be used as a key. I've casted the list to a tuple in the code below, because a tuple _can_ be used as a dict key (if you case: I believe this is because it's immutable whereas a list is not). This tiny change allows reuse of the old code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "text_tok = word_tokenize(shakespeare_text)      \n",
    "text_tok = tuple(text_tok) \n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4(b) Dealing with punctuation\n",
    "rubric={accuracy:4}\n",
    "\n",
    "If you've generated text from part (a), you probably noticed that the way whitespace is handled is not ideal. In particular, whitespace is added after every token, including right before punctuation. \n",
    "\n",
    "1. Modify your code to fix this and show a generated sequence. You can access a list of punctuation characters with `string.punctuation` (and probably somewhere in NLTK as well).\n",
    "2. Show some results for different values of $n$. Note your observations on how the value of `n` affects the quality of the generated text and time taken to generate the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 4(c) other improvements\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Are there other improvements you'd like to make to your word-based Markov model so that the generated text looks like proper English? Feel free to either implement them or just describe what you might want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
