{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49fecb8b-833e-4f1d-979c-29de9ebc3e37",
   "metadata": {},
   "source": [
    "## Class Demo: Recipe generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82734cd-af1f-481d-8609-5519ffaa8c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from urllib.request import urlopen\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc90cc6-d9bc-4747-bc91-ed5dcc065c47",
   "metadata": {},
   "source": [
    "This is a demo for recipe generation using PyTorch and Transformers. \n",
    "For the purpose of this demo, we'll sample 10_000 recipe titles from the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765fad1d-0cc9-4d88-a4d8-357a767fc072",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_recipes_df = pd.read_csv(\"../data/RAW_recipes.csv\")\n",
    "orig_recipes_df = orig_recipes_df.dropna()\n",
    "recipes_df = orig_recipes_df.sample(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7839bff9-07e0-4e3d-be61-2aba64b9fefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150202</th>\n",
       "      <td>original ponhaws   pannhas   ponhaus   scrapple</td>\n",
       "      <td>265164</td>\n",
       "      <td>210</td>\n",
       "      <td>64642</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>['time-to-make', 'course', 'main-ingredient', ...</td>\n",
       "      <td>[224.8, 3.0, 1.0, 66.0, 10.0, 1.0, 15.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['separate pig head into halves', 'remove eyes...</td>\n",
       "      <td>an heirloom, butchering-time recipe impractica...</td>\n",
       "      <td>['pig head', 'water', 'salt', 'pepper', 'sage'...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212835</th>\n",
       "      <td>theodore kyriakou s tomato sauce</td>\n",
       "      <td>142236</td>\n",
       "      <td>85</td>\n",
       "      <td>197023</td>\n",
       "      <td>2005-10-21</td>\n",
       "      <td>['lactose', 'time-to-make', 'course', 'main-in...</td>\n",
       "      <td>[771.7, 104.0, 70.0, 1.0, 16.0, 47.0, 13.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['skin the tomatoes by scoring them and droppi...</td>\n",
       "      <td>this is greek chef and restaurateur theodore k...</td>\n",
       "      <td>['plum tomatoes', 'garlic cloves', 'bay leaves...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228509</th>\n",
       "      <td>ww 6 points   herbed beef burgers</td>\n",
       "      <td>126467</td>\n",
       "      <td>25</td>\n",
       "      <td>120566</td>\n",
       "      <td>2005-06-20</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[334.9, 21.0, 5.0, 20.0, 57.0, 26.0, 7.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['spray grill rack with nonstick spray', 'prep...</td>\n",
       "      <td>from ww magazine.</td>\n",
       "      <td>['whole wheat bread', 'lean ground beef', 'fla...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92561</th>\n",
       "      <td>gingersnap pumpkin ice cream pie</td>\n",
       "      <td>276087</td>\n",
       "      <td>23</td>\n",
       "      <td>705251</td>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[494.9, 36.0, 163.0, 23.0, 10.0, 66.0, 22.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>['for crust:', 'mix together the crust ingredi...</td>\n",
       "      <td>nice change from the standard graham cracker c...</td>\n",
       "      <td>['gingersnaps', 'powdered sugar', 'butter', 'p...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143001</th>\n",
       "      <td>nectarine and radish salsa</td>\n",
       "      <td>374329</td>\n",
       "      <td>45</td>\n",
       "      <td>226377</td>\n",
       "      <td>2009-05-26</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'main-i...</td>\n",
       "      <td>[55.4, 0.0, 37.0, 6.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>['combine all ingredients in a medium bowl and...</td>\n",
       "      <td>from a cooking light i came acroos while puppy...</td>\n",
       "      <td>['nectarines', 'radishes', 'cucumber', 'red on...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181489</th>\n",
       "      <td>sauteed gnocchi</td>\n",
       "      <td>68317</td>\n",
       "      <td>30</td>\n",
       "      <td>50445</td>\n",
       "      <td>2003-08-05</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[150.3, 22.0, 0.0, 21.0, 7.0, 45.0, 0.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>['cook gnocchi according to directions on pack...</td>\n",
       "      <td>something a little different to do with your p...</td>\n",
       "      <td>['gnocchi', 'butter', 'garlic cloves', 'salt',...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54382</th>\n",
       "      <td>citrus poached orange roughy</td>\n",
       "      <td>220709</td>\n",
       "      <td>12</td>\n",
       "      <td>237783</td>\n",
       "      <td>2007-04-04</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[231.2, 10.0, 26.0, 6.0, 57.0, 18.0, 2.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>['cut fish into 4-6 serving-size pieces', 'com...</td>\n",
       "      <td>cilantro adds a wonderful flavor to this easy ...</td>\n",
       "      <td>['orange roughy', 'orange juice', 'water', 'dr...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130872</th>\n",
       "      <td>marinated coleslaw</td>\n",
       "      <td>409922</td>\n",
       "      <td>30</td>\n",
       "      <td>178427</td>\n",
       "      <td>2010-01-24</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[119.4, 8.0, 48.0, 19.0, 4.0, 3.0, 5.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['mix vinegar , sugar , oil , mustard , celery...</td>\n",
       "      <td>from my collection of handwritten recipes 1970...</td>\n",
       "      <td>['cider vinegar', 'sugar', 'oil', 'prepared mu...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27369</th>\n",
       "      <td>bow tie pasta with watercress and avocado crea...</td>\n",
       "      <td>226525</td>\n",
       "      <td>25</td>\n",
       "      <td>246844</td>\n",
       "      <td>2007-05-07</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[781.4, 68.0, 14.0, 11.0, 47.0, 73.0, 25.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['cook pasta according to package directions',...</td>\n",
       "      <td>great little lunch.</td>\n",
       "      <td>['bow tie pasta', 'butter', 'watercress', 'avo...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67766</th>\n",
       "      <td>cube steak in gravy  slow cooker</td>\n",
       "      <td>509192</td>\n",
       "      <td>450</td>\n",
       "      <td>50509</td>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>['weeknight', 'course', 'main-ingredient', 'cu...</td>\n",
       "      <td>[117.5, 1.0, 22.0, 18.0, 7.0, 0.0, 6.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>['i used a 3 qt slow cooker , this did not fil...</td>\n",
       "      <td>i bought some cube steaks on a whim and then w...</td>\n",
       "      <td>['cube steaks', 'flour', 'salt', 'ground black...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name      id  minutes  \\\n",
       "150202    original ponhaws   pannhas   ponhaus   scrapple  265164      210   \n",
       "212835                   theodore kyriakou s tomato sauce  142236       85   \n",
       "228509                  ww 6 points   herbed beef burgers  126467       25   \n",
       "92561                    gingersnap pumpkin ice cream pie  276087       23   \n",
       "143001                         nectarine and radish salsa  374329       45   \n",
       "...                                                   ...     ...      ...   \n",
       "181489                                    sauteed gnocchi   68317       30   \n",
       "54382                        citrus poached orange roughy  220709       12   \n",
       "130872                                 marinated coleslaw  409922       30   \n",
       "27369   bow tie pasta with watercress and avocado crea...  226525       25   \n",
       "67766                    cube steak in gravy  slow cooker  509192      450   \n",
       "\n",
       "        contributor_id   submitted  \\\n",
       "150202           64642  2007-11-13   \n",
       "212835          197023  2005-10-21   \n",
       "228509          120566  2005-06-20   \n",
       "92561           705251  2008-01-03   \n",
       "143001          226377  2009-05-26   \n",
       "...                ...         ...   \n",
       "181489           50445  2003-08-05   \n",
       "54382           237783  2007-04-04   \n",
       "130872          178427  2010-01-24   \n",
       "27369           246844  2007-05-07   \n",
       "67766            50509  2013-11-08   \n",
       "\n",
       "                                                     tags  \\\n",
       "150202  ['time-to-make', 'course', 'main-ingredient', ...   \n",
       "212835  ['lactose', 'time-to-make', 'course', 'main-in...   \n",
       "228509  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "92561   ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "143001  ['60-minutes-or-less', 'time-to-make', 'main-i...   \n",
       "...                                                   ...   \n",
       "181489  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "54382   ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "130872  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "27369   ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "67766   ['weeknight', 'course', 'main-ingredient', 'cu...   \n",
       "\n",
       "                                           nutrition  n_steps  \\\n",
       "150202      [224.8, 3.0, 1.0, 66.0, 10.0, 1.0, 15.0]       11   \n",
       "212835   [771.7, 104.0, 70.0, 1.0, 16.0, 47.0, 13.0]       11   \n",
       "228509     [334.9, 21.0, 5.0, 20.0, 57.0, 26.0, 7.0]        9   \n",
       "92561   [494.9, 36.0, 163.0, 23.0, 10.0, 66.0, 22.0]       10   \n",
       "143001         [55.4, 0.0, 37.0, 6.0, 2.0, 0.0, 4.0]        2   \n",
       "...                                              ...      ...   \n",
       "181489      [150.3, 22.0, 0.0, 21.0, 7.0, 45.0, 0.0]        7   \n",
       "54382      [231.2, 10.0, 26.0, 6.0, 57.0, 18.0, 2.0]       10   \n",
       "130872       [119.4, 8.0, 48.0, 19.0, 4.0, 3.0, 5.0]        5   \n",
       "27369    [781.4, 68.0, 14.0, 11.0, 47.0, 73.0, 25.0]       11   \n",
       "67766        [117.5, 1.0, 22.0, 18.0, 7.0, 0.0, 6.0]       12   \n",
       "\n",
       "                                                    steps  \\\n",
       "150202  ['separate pig head into halves', 'remove eyes...   \n",
       "212835  ['skin the tomatoes by scoring them and droppi...   \n",
       "228509  ['spray grill rack with nonstick spray', 'prep...   \n",
       "92561   ['for crust:', 'mix together the crust ingredi...   \n",
       "143001  ['combine all ingredients in a medium bowl and...   \n",
       "...                                                   ...   \n",
       "181489  ['cook gnocchi according to directions on pack...   \n",
       "54382   ['cut fish into 4-6 serving-size pieces', 'com...   \n",
       "130872  ['mix vinegar , sugar , oil , mustard , celery...   \n",
       "27369   ['cook pasta according to package directions',...   \n",
       "67766   ['i used a 3 qt slow cooker , this did not fil...   \n",
       "\n",
       "                                              description  \\\n",
       "150202  an heirloom, butchering-time recipe impractica...   \n",
       "212835  this is greek chef and restaurateur theodore k...   \n",
       "228509                                  from ww magazine.   \n",
       "92561   nice change from the standard graham cracker c...   \n",
       "143001  from a cooking light i came acroos while puppy...   \n",
       "...                                                   ...   \n",
       "181489  something a little different to do with your p...   \n",
       "54382   cilantro adds a wonderful flavor to this easy ...   \n",
       "130872  from my collection of handwritten recipes 1970...   \n",
       "27369                                 great little lunch.   \n",
       "67766   i bought some cube steaks on a whim and then w...   \n",
       "\n",
       "                                              ingredients  n_ingredients  \n",
       "150202  ['pig head', 'water', 'salt', 'pepper', 'sage'...              6  \n",
       "212835  ['plum tomatoes', 'garlic cloves', 'bay leaves...              8  \n",
       "228509  ['whole wheat bread', 'lean ground beef', 'fla...              9  \n",
       "92561   ['gingersnaps', 'powdered sugar', 'butter', 'p...             11  \n",
       "143001  ['nectarines', 'radishes', 'cucumber', 'red on...              8  \n",
       "...                                                   ...            ...  \n",
       "181489  ['gnocchi', 'butter', 'garlic cloves', 'salt',...              7  \n",
       "54382   ['orange roughy', 'orange juice', 'water', 'dr...              7  \n",
       "130872  ['cider vinegar', 'sugar', 'oil', 'prepared mu...             10  \n",
       "27369   ['bow tie pasta', 'butter', 'watercress', 'avo...              8  \n",
       "67766   ['cube steaks', 'flour', 'salt', 'ground black...             12  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1f1886-8a5c-42c0-97c6-43561ced1dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Set the appropriate device depending upon your hardware. \n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu') \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65696451-317e-4e86-8bcd-5fb27120018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = recipes_df['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d5db3f-e718-4c8f-bbae-26efe1290950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "class TokenizerWrapper():\n",
    "    \"\"\"\n",
    "    A wrapper class for the AutoTokenizer to handle tokenization and provide\n",
    "    custom token-vocabulary mappings. T\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"bert-base-cased\"):        \n",
    "        \"\"\"\n",
    "        Initializes the TokenizerWrapper with a specified model.\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # The wrapper class creates a token-to-vocab mapping\n",
    "        # Let's keep the ids corresponding to special tokens.  \n",
    "        # 0 --> [PAD], 101 --> [CLS], 102 --> [SEP]  \n",
    "        self.token_id_to_vocab_id = {0: 0, 101: 1, 102: 2}\n",
    "        self.vocab_id_to_token_id = {0: 0, 1: 101, 2:102}\n",
    "        self.vocab_id = len(self.vocab_id_to_token_id)\n",
    "        self.padding_len = None \n",
    "\n",
    "    def build_dictionary(self, list_of_recipes: list):\n",
    "        \"\"\"\n",
    "        Processes a list of captions to build and update the vocabulary based on the tokens found in the captions.\n",
    "        This function also finds the maximum length of the tokenized captions to set the padding length.\n",
    "    \n",
    "        \"\"\"\n",
    "        # Tokenize all recipes to find the unique tokens and the maximum length\n",
    "        tokenized_outputs = self.tokenizer(list_of_recipes, add_special_tokens=False)\n",
    "        all_token_ids = set(token for sublist in tokenized_outputs.input_ids for token in sublist)\n",
    "    \n",
    "        # Update the custom token-vocabulary mapping\n",
    "        for token_id in all_token_ids:\n",
    "            if token_id not in self.token_id_to_vocab_id:\n",
    "                self.token_id_to_vocab_id[token_id] = self.vocab_id\n",
    "                self.vocab_id_to_token_id[self.vocab_id] = token_id\n",
    "                self.vocab_id += 1\n",
    "    \n",
    "        # Set the padding length to the length of the longest tokenized recipe\n",
    "        self.padding_len = max(len(tokens) for tokens in tokenized_outputs.input_ids)\n",
    "    \n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        \"\"\"\n",
    "        Returns the size of the custom vocabulary.\n",
    "        \"\"\"\n",
    "        assert len(self.token_id_to_vocab_id) == len(self.vocab_id_to_token_id)\n",
    "        return len(self.token_id_to_vocab_id)\n",
    "\n",
    "\n",
    "    def tokenize(self, text: str) -> list:\n",
    "        \"\"\"\n",
    "        Tokenizes a text string into custom vocabulary IDs, using the built dictionary. \n",
    "        Requires the dictionary to be built first.\n",
    "    \n",
    "        Parameters:\n",
    "            text (str): The text to tokenize.\n",
    "    \n",
    "        Returns:\n",
    "            list of int: A list of custom vocabulary IDs corresponding to the text tokens.\n",
    "        \"\"\"\n",
    "        assert self.padding_len is not None, 'Call build_dictionary first.'\n",
    "        # Tokenize the text with the maximum length set to the previously found maximum padding length\n",
    "        \n",
    "        tokenized_output = self.tokenizer(text, add_special_tokens=False, padding='max_length', max_length=self.padding_len, truncation=True)\n",
    "        return [self.token_id_to_vocab_id.get(token_id, 0)  # Default to [PAD] if token_id is not found\n",
    "                for token_id in tokenized_output.input_ids]\n",
    "        \n",
    "    \n",
    "    def decode(self, vocab_list: list) -> str:\n",
    "        \"\"\"\n",
    "        Decodes a list of custom vocabulary IDs back into the original text string.\n",
    "\n",
    "        Parameters:\n",
    "            vocab_list (list of int): A list of custom vocabulary IDs to decode.\n",
    "\n",
    "        Returns:\n",
    "            str: The decoded text string.\n",
    "        \"\"\"        \n",
    "        token_list = [self.vocab_id_to_token_id[vocab_id] for vocab_id in vocab_list]\n",
    "        decoded_string = self.tokenizer.decode(token_list, skip_special_tokens=True)\n",
    "        return decoded_string.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab21b95b-135d-4b98-ad63-7e48e9b89ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dictionary for our tokenizer  \n",
    "from tqdm import tqdm, trange \n",
    "tokenizer_wrapper = TokenizerWrapper()\n",
    "tokenizer_wrapper.build_dictionary(recipes_df[\"name\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a5e6de-63b0-438f-be17-bb8b61e3c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: delicious puffy oven baked apple pancake\n",
      "Tokens: [2416, 3311, 2145, 1711, 1903, 2013, 2517, 1618, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded caption: delicious puffy oven baked apple pancake\n"
     ]
    }
   ],
   "source": [
    "recipe_tokens = tokenizer_wrapper.tokenize(recipes_df['name'].iloc[10])\n",
    "decoeded_recipe = tokenizer_wrapper.decode(recipe_tokens)\n",
    "print('Caption:', recipes_df['name'].iloc[10])\n",
    "print('Tokens:', recipe_tokens)\n",
    "print('Decoded caption:', decoeded_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd9a66e-40f9-4dd4-a581-b7f7804ea1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3657"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer_wrapper.get_vocab_size()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405676b-1c97-4c37-a71e-a07866a3956b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dbb5e-5213-416d-92f1-1a838316b28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d127ebca-f8f7-4397-ac11-33336966e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(data_df, tokenizer_wrapper):    \n",
    "    dataset = []\n",
    "    for row_id in trange(len(data_df)):\n",
    "        reicpe_tokens = torch.tensor(tokenizer_wrapper.tokenize(data_df['name'].iloc[row_id]))  # SOLUTION\n",
    "        dataset.append({'token': reicpe_tokens})\n",
    "    return dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be52cda2-aec7-4e96-b653-b0115b86f646",
   "metadata": {},
   "source": [
    "Let's create train and test datasets by calling `build_data` on train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54299ff0-a919-4453-84c7-c3b4b417fd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "  0%|                                                  | 0/8000 [00:00<?, ?it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|████████████████████████████████████| 8000/8000 [00:00<00:00, 20221.48it/s]\n",
      "100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 20538.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(recipes_df, test_size=0.2, random_state=123)\n",
    "train_data = build_data(train_df, tokenizer_wrapper)\n",
    "test_data = build_data(test_df, tokenizer_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "140dabb0-d937-49c8-aa19-11cb67b4dcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocab size is 3657.\n"
     ]
    }
   ],
   "source": [
    "# Get the dimension of the image feature\n",
    "vocab_size = tokenizer_wrapper.get_vocab_size()\n",
    "print(f'The vocab size is {vocab_size}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3afe702f-0349-44ce-82f1-4f4f5d4f5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchDataset():\n",
    "    def __init__(self, data, pad_vocab_id=0):\n",
    "        self.data = data\n",
    "        self.pad_tensor = torch.tensor([pad_vocab_id])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        # Retrieve the next sequence of tokens from the current index\n",
    "        # by excluding the first token of the current sequence and appending a padding token at the end.        \n",
    "        target_sequence = torch.cat([self.data[ind]['token'][1:], self.pad_tensor]) # SOLUTION\n",
    "        return self.data[ind]['token'], target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d993084-a56d-45fe-8438-48d6f88c6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PytorchDataset(train_data)\n",
    "test_dataset = PytorchDataset(test_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f735587-d16d-4e5d-aaf9-0ba8bf29b533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 23])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's get a batch of data from DataLoader\n",
    "train_text, train_target = next(iter(train_dataloader))\n",
    "train_text = train_text.to(device)\n",
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103cff6c-b65c-4c5f-bf05-b1ddc3efbe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  61, 1465, 1973,  209, 2422,  391,  743, 3255,  382, 2170, 1231,   59,\n",
       "        3050, 1123,  879, 1607,    0,    0,    0,    0,    0,    0,    0],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a019a4e-38b1-4d93-9a06-9b9da5c9faed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1465, 1973,  209, 2422,  391,  743, 3255,  382, 2170, 1231,   59, 3050,\n",
       "        1123,  879, 1607,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd67dac-e5e7-4a68-9b05-3f901673b1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'croatian turkey soup with sour cream and dill ajngemahtes'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_wrapper.decode(train_text[11].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "149533c9-778d-443e-8080-723c95bfb8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##roatian turkey soup with sour cream and dill ajngemahtes'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_wrapper.decode(train_target[11].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02094388-1b47-4f8e-9218-8167425fe48d",
   "metadata": {},
   "source": [
    "This is called autoregressive training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "426427fd-d3b9-4484-b3da-db0cfedaa6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PositionalEncoding model is already defined for you.  Do not change this class.\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03c05e-435e-45a4-a86f-7944414edfee",
   "metadata": {},
   "source": [
    "**PyTorch [TransformerDecoderLayer](https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html)**\n",
    "\n",
    "- Encoder decoder models (Sequence to sequence models) \n",
    "- Decoder only\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9be74fc-4b38-4f60-bc2b-45d5818314d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeGenerator(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, num_layers, vocab_size, device, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the RecipeGenerator which uses a transformer decoder architecture\n",
    "        for generating image captions.\n",
    "\n",
    "        Parameters:\n",
    "            d_model (int): The number of expected features in the encoder/decoder inputs.\n",
    "            n_heads (int): The number of heads in the multiheadattention models.\n",
    "            num_layers (int): The number of sub-decoder-layers in the transformer.\n",
    "            vocab_size (int): The size of the vocabulary.\n",
    "            device (torch.device): The device on which the model will be trained.\n",
    "            dropout (float): The dropout value used in PositionalEncoding and TransformerDecoderLayer.\n",
    "        \"\"\"        \n",
    "        super(RecipeGenerator, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.device = device\n",
    "        # Positional Encoding to add position information to input embeddings\n",
    "        self.pos_encoding = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "\n",
    "        self.TransformerDecoder = nn.TransformerDecoder(\n",
    "            decoder_layer=nn.TransformerDecoderLayer(d_model=d_model, nhead=n_heads, dropout=dropout), \n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Embedding layer for converting input text tokens into vectors\n",
    "        self.text_embedding = nn.Embedding(vocab_size , d_model)\n",
    "\n",
    "        # Final linear layer to map the output of the transformer decoder to vocabulary size        \n",
    "        self.linear_layer = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        # END SOLUTION\n",
    "\n",
    "        # Initialize the weights of the model\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights of the model to small random values.\n",
    "        \"\"\"\n",
    "        initrange = 0.1\n",
    "        # BEGIN SOLUTION\n",
    "        self.text_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear_layer.bias.data.zero_()\n",
    "        self.linear_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, text):\n",
    "        # Get the embeded input\n",
    "        encoded_text = self.embed_text(text)        \n",
    "\n",
    "        # Get transformer output\n",
    "        transformer_output = self.decode(encoded_text)\n",
    "\n",
    "        # Final linear layer (unembedding layer)\n",
    "        return self.linear_layer(transformer_output)\n",
    "    \n",
    "    def embed_text(self, text):\n",
    "        embedding = self.text_embedding(text) * math.sqrt(self.d_model)\n",
    "        return self.pos_encoding(embedding.permute(1, 0, 2))\n",
    "    \n",
    "    def decode(self, encoded_text):\n",
    "        # Get the length of the sequences to be decoeded. This is needed to generate the causal masks\n",
    "        seq_len = encoded_text.size(0)\n",
    "        causal_mask = self.generate_mask(seq_len)\n",
    "        dummy_memory = torch.zeros_like(encoded_text)\n",
    "        return self.TransformerDecoder(tgt=encoded_text, memory=dummy_memory, tgt_mask=causal_mask)\n",
    "    \n",
    "    def generate_mask(self, size):\n",
    "        mask = torch.triu(torch.ones(size, size, device=self.device), 1)\n",
    "        return mask.float().masked_fill(mask == 1, float('-inf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fb26974-ebd5-45f0-95ec-9389cfa1ef8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "size = 10\n",
    "mask = torch.triu(torch.ones(size, size), 1)\n",
    "mask.float().masked_fill(mask == 1, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aec3e665-1988-4c7a-8337-41a81d0a792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try your model. \n",
    "# Define the hyperparameters and initalize the model. Feel free to change these hyperparameters. \n",
    "d_model = 256 \n",
    "n_heads = 4\n",
    "num_layers = 8\n",
    "model = RecipeGenerator(d_model=d_model, n_heads=n_heads, num_layers=num_layers, vocab_size=vocab_size, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca2660f0-5eae-463e-9ea2-48f090ac5bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3166,  558, 2485,  ...,    0,    0,    0],\n",
       "        [  59,  316, 1767,  ...,    0,    0,    0],\n",
       "        [ 487,  540, 3646,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [  74,  977,  438,  ...,    0,    0,    0],\n",
       "        [  60, 2294, 1471,  ...,    0,    0,    0],\n",
       "        [ 651, 1581, 3311,  ...,    0,    0,    0]], device='mps:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e55dbf9a-f866-40e7-a934-a4a48ef0de90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 64, 3657])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass inputs to your model\n",
    "output = model(train_text)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39544a5d-b332-4cff-807c-04d3a2eb08ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3657"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76417d4a-6e75-4c60-9fa7-433798366f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 23])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1c1cc1a-765f-4ed4-89ff-d900cd5a25a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 64, 3657])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed75fdb-733e-4b83-a5d3-43345551cef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52a533ea-631e-4fc6-a24a-14ec898fff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, criterion, optimizer, train_dataloader, test_dataloader, epochs=5, patience=5, clip_norm=1.0):\n",
    "    train_losses, test_losses = [], []\n",
    "    consec_increases, verbose = 0, True\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for train_text, target_seq in train_dataloader:\n",
    "            train_text, target_seq = train_text.to(device), target_seq.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_text).permute(1, 2, 0)  # Ensure output is in correct shape for loss calculation\n",
    "            loss = criterion(output, target_seq)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_text, target_seq in test_dataloader:\n",
    "                test_text, target_seq = test_text.to(device), target_seq.to(device)\n",
    "                output = model(test_text).permute(1, 2, 0)\n",
    "                test_loss += criterion(output, target_seq).item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_dataloader))\n",
    "        test_losses.append(test_loss / len(test_dataloader))\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss {train_losses[-1]:.4f}, Test Loss {test_losses[-1]:.4f}\")\n",
    "\n",
    "        if epoch > 0 and test_losses[-1] > test_losses[-2] * (1 + 1e-5):\n",
    "            consec_increases += 1\n",
    "        else:\n",
    "            consec_increases = 0\n",
    "\n",
    "        if consec_increases >= patience:\n",
    "            print(f\"Stopped early at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "895144a0-8d32-4841-b284-6f059a8f78a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 7.5154, Test Loss 6.9418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m      8\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Ignore the padding index\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 14\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, epochs, patience, clip_norm)\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target_seq)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/575/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:59\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m             norms\u001b[38;5;241m.\u001b[39mextend([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\n\u001b[1;32m     61\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the optimizer and the loss function. Feel free to change the hyperparameters. \n",
    "\n",
    "num_epoch = 20\n",
    "clip_norm = 1.0\n",
    "lr = 5e-5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0) # Ignore the padding index\n",
    "train_losses, test_losses = trainer(model, criterion, optimizer,train_dataloader, test_dataloader, epochs= num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1aa4e-8584-4dc3-893c-c35a53b3b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(model, device, max_recipe_length=39, seed = 10, end_vocab=2):\n",
    "    \"\"\"\n",
    "    Generates a recipe for an image using the specified model and device.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The trained model used for generating captions.\n",
    "        device (torch.device): The device (e.g., CPU or GPU) to which tensors will be sent for model execution.\n",
    "        max_caption_length (int, optional): The maximum length of the generated caption. Defaults to 100.\n",
    "        start_vocab (int, optional): The vocabulary index used to signify the start of a caption. Defaults to 1.\n",
    "        end_vocab (int, optional): The vocabulary index used to signify the end of a caption. Defaults to 2.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: An array containing the sequence of vocabulary indices representing the generated caption.\n",
    "        \n",
    "    \"\"\"    \n",
    "    context = torch.tensor([[seed]]).to(device)\n",
    "    for _ in range(max_recipe_length):\n",
    "        logits = model(context)[-1]\n",
    "        probabilities = torch.softmax(logits, dim=-1).flatten(start_dim=1)\n",
    "        next_vocab = torch.multinomial(probabilities, num_samples=1)\n",
    "        context = torch.cat([context, next_vocab], dim=1)\n",
    "        if next_vocab.item() == end_vocab:\n",
    "            break\n",
    "    return context.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229871ab-e2dd-460e-9f00-3a8d74f27f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = generate_recipe(model, device, max_recipe_length=20, seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308b243-b184-45cb-91e2-cd22f67e4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_recipe = tokenizer_wrapper.decode(recipe)\n",
    "generated_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50a895-c62f-4d2c-ad18-b19c573bc2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:575]",
   "language": "python",
   "name": "conda-env-575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
